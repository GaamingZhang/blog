---
date: 2025-07-01
author: Gaaming Zhang
isOriginal: false
article: true
category:
  - 操作系统
tag:
  - 操作系统
---

# 上下文切换：操作系统多任务的核心机制

## 什么是上下文切换

**上下文切换**（Context Switch）是操作系统实现多任务并发执行的核心机制。当 CPU 从一个进程或线程切换到另一个时，需要保存当前任务的执行状态（上下文），然后恢复新任务的执行状态，这个过程就是上下文切换。

这就像你在阅读一本书时被电话打断：你需要记住当前读到第几页（保存上下文），接电话（执行新任务),通话结束后再翻回之前的页码继续阅读（恢复上下文）。

---

## 上下文包含什么

上下文是 CPU 恢复某个任务执行所需的所有信息，主要包括：

**CPU 寄存器状态**：
- 通用寄存器：存储计算中间结果
- 程序计数器（PC）：指向下一条要执行的指令
- 栈指针（SP）：指向当前栈顶位置
- 状态寄存器：包含条件码、中断标志等
- 段寄存器：代码段、数据段、栈段的位置

**内存管理信息**：
- 页表基址寄存器（如 x86 的 CR3）：指向进程的虚拟内存映射表
- TLB（地址转换缓存）：虚拟地址到物理地址的快速查找缓存

**内核栈**：
- 每个进程/线程有独立的内核栈
- 保存系统调用参数、返回地址等

**其他状态**：
- 浮点运算单元（FPU）状态
- SIMD 寄存器（高级向量计算）
- 调试寄存器和性能计数器

---

## 上下文切换的类型

### 进程上下文切换

进程切换是开销最大的一种，因为不同进程拥有完全独立的地址空间。

**需要切换的内容**：
- 所有 CPU 寄存器
- 页表（虚拟内存映射关系）
- TLB 缓存（必须刷新）
- 打开的文件描述符信息
- 信号处理信息
- 进程优先级和调度信息

**触发条件**：
- 时间片用完（时钟中断触发）
- 进程阻塞（等待 I/O、睡眠、等待锁）
- 进程主动让出 CPU
- 进程终止
- 更高优先级进程就绪

### 线程上下文切换

**同一进程内的线程切换**开销较小：
- 共享相同的虚拟内存空间（不需要切换页表）
- 不需要刷新 TLB
- 共享打开的文件描述符
- 只需切换 CPU 寄存器、程序计数器和栈指针

**不同进程的线程切换**等同于进程切换，开销相同。

### 中断上下文切换

硬件中断发生时：
1. CPU 自动保存部分寄存器（如程序计数器）
2. 跳转到中断处理程序
3. 处理完成后恢复寄存器
4. 返回被中断的任务

这不是完整的进程切换，但会打断当前执行流，频繁中断也会影响性能。

### 系统调用上下文切换

用户态程序调用系统功能（如读文件、申请内存）时，需要从用户态切换到内核态：
- 特权级切换（用户态 Ring 3 → 内核态 Ring 0）
- 栈切换（用户栈 → 内核栈）
- 保存部分寄存器

开销小于进程切换，但仍有成本。

---

## 上下文切换的完整过程

以进程 A 切换到进程 B 为例，整个过程分为三个阶段：

```
第一阶段：保存进程 A 的上下文
┌─────────────────────────────────────────┐
│ 1. 触发切换（时钟中断/系统调用/阻塞）    │
│ 2. 进入内核态                            │
│ 3. 保存 A 的 CPU 寄存器到 PCB            │
│    - 通用寄存器（计算结果）              │
│    - 程序计数器（执行位置）              │
│    - 栈指针（栈顶位置）                  │
│    - 状态寄存器（CPU 状态）              │
│ 4. 保存 A 的浮点/向量寄存器状态          │
│ 5. 更新 A 的状态（运行 → 就绪/阻塞）    │
└─────────────────────────────────────────┘

第二阶段：调度决策
┌─────────────────────────────────────────┐
│ 6. 调用调度器                            │
│ 7. 从就绪队列选择进程 B                  │
│    - 根据调度算法（CFS/优先级等）        │
│ 8. 更新 B 的状态（就绪 → 运行）          │
└─────────────────────────────────────────┘

第三阶段：恢复进程 B 的上下文
┌─────────────────────────────────────────┐
│ 9. 切换地址空间（页表）                  │
│    - 更新页表基址寄存器                  │
│    - 刷新 TLB（清空地址转换缓存）        │
│ 10. 切换内核栈                           │
│ 11. 从 B 的 PCB 恢复 CPU 寄存器          │
│ 12. 恢复 B 的浮点/向量寄存器             │
│ 13. 跳转到 B 的程序计数器位置            │
│ 14. 进程 B 继续执行                      │
└─────────────────────────────────────────┘
```

**关键点**：PCB（进程控制块）是内核为每个进程维护的数据结构，保存了进程的所有上下文信息。

---

## 上下文切换的开销

### 时间成本

典型的上下文切换时间（现代 CPU）：
- **进程切换**：1-10 微秒
- **线程切换**（同进程）：0.1-1 微秒
- **系统调用**：0.05-0.5 微秒

开销分为两部分：

**直接开销**（约占 20-30%）：
- 保存/恢复寄存器：~100 纳秒
- 切换页表：~50 纳秒
- 内核调度代码执行：~500 纳秒
- 总计：~1 微秒

**间接开销**（约占 70-80%，影响更大）：
- TLB 刷新导致的地址转换变慢
- CPU 缓存失效导致的内存访问变慢
- 流水线冲刷导致的指令执行变慢
- 分支预测失效导致的跳转变慢

### TLB 刷新的影响

**TLB（Translation Lookaside Buffer）** 是 CPU 内部的高速缓存,存储最近使用的虚拟地址到物理地址的映射。

```
为什么需要 TLB：
┌──────────────────────────────────────┐
│ 没有 TLB：每次内存访问               │
│ 虚拟地址 → 查页表 → 物理地址        │
│ 延迟：100+ 个时钟周期                │
└──────────────────────────────────────┘

┌──────────────────────────────────────┐
│ 有 TLB：大部分内存访问               │
│ 虚拟地址 → 查 TLB → 物理地址        │
│ 延迟：1-2 个时钟周期                 │
└──────────────────────────────────────┘
```

**为什么进程切换要刷新 TLB**：

不同进程有不同的虚拟地址空间。例如：
- 进程 A：虚拟地址 0x1000 → 物理地址 0xA000
- 进程 B：虚拟地址 0x1000 → 物理地址 0xB000

如果不刷新 TLB，进程 B 访问虚拟地址 0x1000 时会命中 TLB，得到错误的物理地址 0xA000，导致访问进程 A 的内存——这是严重的安全问题。

因此进程切换时必须刷新 TLB，但这意味着新进程开始时每次地址访问都会 TLB miss，需要查询页表，导致性能下降。

**优化**：
- 现代 CPU 支持 PCID（进程上下文标识符），允许不同进程的 TLB 条目共存
- 使用大页（Huge Pages）减少 TLB 条目数量
- 线程切换不需要刷新 TLB（共享地址空间）

### CPU 缓存失效

现代 CPU 有多层缓存（L1/L2/L3），上下文切换会导致缓存内容部分或完全失效：

```
┌─────────────────────────────────────────┐
│ 进程 A 运行时                            │
│ - L1 缓存：充满 A 的指令和数据，命中率高 │
│ - L2 缓存：包含 A 的热点数据             │
│ - L3 缓存：包含更多 A 的数据             │
│ - 分支预测器：已学习 A 的分支模式       │
└─────────────────────────────────────────┘
                  ↓ 切换到进程 B
┌─────────────────────────────────────────┐
│ 进程 B 运行时                            │
│ - L1 缓存：几乎完全失效，需重新加载      │
│ - L2 缓存：部分失效                      │
│ - L3 缓存：部分保留（跨核心共享）        │
│ - 分支预测器：几乎完全失效               │
└─────────────────────────────────────────┘
```

**缓存预热时间**（恢复到正常命中率所需时间）：
- L1 Cache：1-2 微秒
- L2 Cache：5-10 微秒
- L3 Cache：50-100 微秒

在此期间，CPU 需要频繁访问内存，性能大幅下降。

---

## 触发上下文切换的常见场景

### 时间片耗尽

操作系统给每个进程分配一定的 CPU 时间（时间片）。时间片用完后，时钟中断触发，调度器选择下一个进程运行。

Linux 使用完全公平调度器（CFS），没有固定时间片，而是根据进程的"虚拟运行时间"动态调度，确保每个进程获得公平的 CPU 时间。

### 进程阻塞

当进程执行以下操作时会主动让出 CPU：
- 等待 I/O 完成（读写文件、网络请求）
- 等待锁（其他线程占用）
- 主动睡眠（sleep、等待子进程）

这些操作会将进程状态设置为"阻塞"，触发调度器选择其他就绪进程运行。

### 更高优先级进程就绪

实时进程（SCHED_FIFO、SCHED_RR）优先级高于普通进程。当实时进程就绪时，会立即抢占当前运行的普通进程。

### 中断处理

硬件中断（如网络数据到达、磁盘 I/O 完成）会暂停当前进程，执行中断处理程序。中断处理完成后，可能唤醒等待该事件的进程，触发重新调度。

---

## 减少上下文切换的优化策略

### 控制线程数量

过多线程会导致频繁切换。最佳实践：
- 使用线程池，限制并发线程数量（通常为 CPU 核心数的 1-2 倍）
- 对于 I/O 密集型任务，使用异步 I/O 代替多线程

### 使用协程

协程是用户态的轻量级线程，切换不需要陷入内核：
- 切换速度快（纳秒级 vs 微秒级）
- 可以支持大量并发（百万级）
- 适合 I/O 密集型场景（如 Web 服务器）

Go 的 goroutine 和 Python 的 asyncio 都是协程的实现。

### 绑定 CPU 亲和性

将进程/线程绑定到特定 CPU 核心，可以：
- 减少进程在不同 CPU 间迁移
- 提高 CPU 缓存命中率
- 减少 TLB 刷新

### 减少锁竞争

锁竞争会导致线程频繁阻塞和唤醒。优化方法：
- 减小锁的粒度（临界区尽量短）
- 使用读写锁（读多写少场景）
- 使用无锁数据结构（基于原子操作）
- 使用 CAS（Compare-And-Swap）算法

### 批处理

将多次操作合并为一次，减少系统调用次数：
- 批量读写文件而非逐个字节
- 使用缓冲 I/O
- 网卡中断合并（减少中断次数）

### 使用用户态调度

用户态线程（Green Threads）由用户态调度器管理，避免内核上下文切换：
- 优势：切换速度快，可支持大量并发
- 劣势：需要配合非阻塞 I/O，单独使用无法利用多核

最佳实践：M:N 线程模型（如 Go 的 GMP 模型）
- M 个用户态协程
- N 个内核线程（通常等于 CPU 核心数）
- 用户态调度器将协程分配到内核线程
- 结合了用户态快速切换和多核利用的优势

---

## 监控上下文切换

### 查看系统整体情况

**vmstat** 查看每秒上下文切换次数：
- 正常值：几百到几千次/秒
- 异常值：几万以上/秒，表明可能存在性能问题

### 查看进程级别

**pidstat** 可以查看单个进程的切换情况：
- **自愿切换**（cswch/s）：进程主动放弃 CPU（等待 I/O、睡眠、等待锁）
  - 数值高：可能是 I/O 密集或锁竞争严重
- **非自愿切换**（nvcswch/s）：时间片用完被强制切换
  - 数值高：可能是 CPU 竞争激烈或线程过多

### 性能分析

**perf** 可以深入分析切换行为：
- 记录切换事件并查看调用栈
- 分析切换热点（哪些函数导致频繁切换）
- 测量 CPU 迁移（进程在不同 CPU 间切换）

---

## 不同调度策略的影响

Linux 支持多种调度策略，影响切换频率：

**SCHED_NORMAL（默认）**：
- 普通进程，完全公平调度（CFS）
- 动态调整时间片，公平分配 CPU

**SCHED_FIFO（实时，先进先出）**：
- 运行直到阻塞或主动让出
- 不会被同优先级进程抢占
- 减少切换，但需谨慎使用（可能饿死其他进程）

**SCHED_BATCH（批处理）**：
- 适合 CPU 密集型任务
- 减少抢占，降低切换频率
- 提高吞吐量但增加延迟

**SCHED_IDLE（空闲）**：
- 只在 CPU 空闲时运行
- 最低优先级

---

## 常见问题

### Q1: 进程切换和线程切换的开销有什么区别？

**主要区别**在于虚拟内存和 TLB：

| 项目         | 进程切换             | 线程切换（同进程） |
| ------------ | -------------------- | ------------------ |
| 虚拟内存空间 | 需要切换页表         | 共享，不需要切换   |
| TLB 刷新     | 需要（地址空间变化） | 不需要             |
| CPU 缓存     | 大量失效             | 部分失效           |
| 开销         | 1-10 微秒            | 0.1-1 微秒         |

**关键**：页表切换和 TLB 刷新是进程切换最大的开销来源。同进程内的线程切换只需切换寄存器和栈，因此快得多。

### Q2: 什么情况下会发生大量上下文切换？如何优化？

**常见导致大量切换的场景**：

**线程/进程过多**：
- 问题：100 个线程竞争 4 个 CPU 核心
- 现象：大量非自愿切换
- 优化：使用线程池，限制并发数量

**锁竞争严重**：
- 问题：多个线程频繁争抢同一个锁
- 现象：大量自愿切换
- 优化：减小锁粒度、使用读写锁、使用无锁数据结构

**I/O 密集型应用**：
- 问题：频繁的文件读写、网络请求
- 现象：大量自愿切换（等待 I/O）
- 优化：使用异步 I/O、批量处理、使用缓冲

**不合理的睡眠/唤醒**：
- 问题：忙等待（循环调用 sleep）
- 优化：使用条件变量（高效等待机制）

### Q3: TLB 是什么？为什么上下文切换要刷新 TLB？

**TLB（地址转换后备缓冲区）** 缓存虚拟地址到物理地址的映射：
- TLB 命中：1-2 个时钟周期
- TLB 未命中：需要查询页表，几十到几百个时钟周期

**为什么要刷新**：
不同进程有不同的虚拟地址空间。相同的虚拟地址在不同进程中映射到不同的物理地址。如果不刷新 TLB，会访问到错误的物理内存，导致严重的安全问题。

**优化策略**：
- **使用大页**：普通页 4KB，大页 2MB 或 1GB。TLB 条目数量不变，但覆盖范围大大增加
- **PCID 技术**：TLB 条目带进程标识，切换时不需要完全刷新
- **CPU 亲和性**：进程绑定到固定 CPU，减少迁移，保持 TLB 热度

### Q4: 用户态切换和内核态切换有什么区别？

**内核态上下文切换**（进程/线程切换）：
- 由内核调度器管理
- 需要陷入内核（Ring 0）
- 保存完整的进程/线程状态
- 切换页表和地址空间（进程切换）
- 时间：1-10 微秒

**用户态上下文切换**（协程/纤程）：
- 由用户态调度器管理
- 不需要陷入内核
- 只保存/恢复寄存器和栈
- 不切换地址空间
- 时间：10-100 纳秒（快 100 倍）

**性能对比**：
- 创建开销：内核线程 ~10 微秒，协程 ~100 纳秒
- 并发能力：内核线程数千，协程百万级
- 适用场景：内核线程适合 CPU 密集型，协程适合 I/O 密集型

**最佳实践**：M:N 线程模型
- M 个用户态协程（快速切换）
- N 个内核线程（利用多核）
- 结合两者优势

---

## 核心要点

**上下文切换的本质**：保存当前任务状态，恢复新任务状态，是操作系统实现多任务的基础。

**开销来源**：
- 直接开销：保存/恢复寄存器、切换页表（约 1 微秒）
- 间接开销：TLB 刷新、CPU 缓存失效、流水线冲刷（占 70-80%）

**优化原则**：
- 减少切换次数：控制线程数量、使用异步 I/O
- 降低切换成本：使用协程、绑定 CPU 亲和性、减少锁竞争

**监控指标**：
- 自愿切换：反映 I/O 等待和锁竞争
- 非自愿切换：反映 CPU 竞争和线程过多
- 正常值：几百到几千/秒，异常值：几万以上/秒
