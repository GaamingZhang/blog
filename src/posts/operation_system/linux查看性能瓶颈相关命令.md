---
date: 2025-07-01
author: Gaaming Zhang
isOriginal: false
article: true
category:
  - 操作系统
tag:
  - 操作系统
---

# Linux 性能诊断：发现系统瓶颈的方法

## 性能瓶颈的四个维度

Linux 系统性能瓶颈通常来自四个方面：**CPU、内存、磁盘 I/O、网络**。理解这四个维度的关系和相互影响，是性能诊断的基础。

### 为什么需要性能诊断

**预防性维护**：
- 提前发现性能下降趋势
- 避免系统故障和宕机
- 为扩容提供数据支持

**优化资源利用**：
- 识别资源浪费
- 降低基础设施成本
- 提升系统响应速度

**问题定位**：
- 快速找到性能瓶颈
- 区分应用问题还是系统问题
- 提供优化方向

---

## 性能诊断方法论

### USE 方法（资源视角）

**Utilization**（使用率）：资源被使用的时间占比
- CPU 使用率、内存使用率、磁盘使用率
- 高使用率表明资源可能不足

**Saturation**（饱和度）：资源无法满足请求的程度
- 运行队列长度、等待队列长度
- 饱和表明资源已成为瓶颈

**Errors**（错误数）：错误事件的数量
- 网络丢包、磁盘错误、内存错误
- 错误往往指向硬件或配置问题

### RED 方法（服务视角）

**Rate**（请求速率）：每秒处理的请求数
**Errors**（错误率）：失败请求的比例
**Duration**（延迟）：请求处理时间

适用于面向服务的性能分析。

### 分层分析法

```
系统层面（整体视图）
    ↓
进程层面（资源消耗者）
    ↓
应用层面（代码热点）
```

从宏观到微观，逐步缩小问题范围。

### 关联分析

不同指标之间存在关联关系，需要综合判断：

- **高 Load + 低 CPU 使用率** → 可能是 I/O 瓶颈
- **高 CPU + 大量上下文切换** → 可能是线程过多
- **高内存使用 + 频繁 swap** → 内存不足
- **网络延迟 + 丢包** → 网络链路问题

---

## CPU 性能分析

### CPU 的三个关键指标

**使用率**（Utilization）：
- **us**（user）：用户态 CPU 时间，应用程序计算
- **sy**（system）：内核态 CPU 时间，系统调用
- **wa**（iowait）：等待 I/O 的 CPU 时间
- **id**（idle）：空闲 CPU 时间

**负载**（Load Average）：
- 过去 1、5、15 分钟的平均运行队列长度
- 包括正在运行和等待运行的进程
- 理想值：约等于 CPU 核心数

**上下文切换**：
- 自愿切换：进程主动等待（I/O、锁）
- 非自愿切换：时间片用完被抢占

### 诊断 CPU 瓶颈的思路

**第一步：查看整体状况**
使用 `top` 或 `htop` 快速查看：
- CPU 使用率分布（us、sy、wa、id）
- Load Average 与 CPU 核心数的比例
- 是否有进程占用异常高的 CPU

**第二步：识别瓶颈类型**

**计算密集型**：
- 特征：us% 高（> 70%），wa% 低（< 5%）
- 原因：算法效率低、无限循环、大量计算
- 工具：perf、strace 分析热点函数

**I/O 等待型**：
- 特征：wa% 高（> 30%），id% 低
- 原因：磁盘 I/O 慢，CPU 在等待数据
- 工具：iostat、iotop 分析磁盘

**系统调用密集型**：
- 特征：sy% 高（> 20%）
- 原因：频繁系统调用、锁竞争
- 工具：strace 统计系统调用

**过度竞争型**：
- 特征：高 Load、高上下文切换、CPU 使用不高
- 原因：线程/进程过多，频繁切换
- 工具：pidstat、vmstat 查看切换次数

### 常用工具及其作用

**top/htop**：实时监控，快速概览
**vmstat**：虚拟内存统计，查看运行队列和上下文切换
**mpstat**：多核 CPU 监控，识别负载不均衡
**pidstat**：进程级 CPU 统计，找出高 CPU 进程
**perf**：性能剖析，找出代码热点
**strace**：系统调用跟踪，分析系统调用频率

---

## 内存性能分析

### 内存的层次结构

```
物理内存（RAM）
    ↓
页面缓存（Page Cache）：文件系统缓存
    ↓
缓冲区（Buffer）：块设备缓存
    ↓
交换空间（Swap）：磁盘上的虚拟内存
```

### 内存的关键概念

**Total**：总物理内存
**Used**：已使用内存（包括缓存）
**Free**：完全未使用的内存
**Buff/Cache**：缓存，可回收
**Available**：实际可用内存（Free + 可回收缓存）

重要：**Linux 会尽量使用内存作为缓存**，free 很小是正常的，应该关注 available。

### 内存压力的判断

**正常状态**：
- Available > Total 的 20%
- Swap 使用很少或为 0
- 没有频繁的 swap in/out

**内存压力**：
- Available < Total 的 10%
- Swap 使用持续增加
- vmstat 显示 si/so（swap in/out）持续大于 0

**内存泄漏**：
- 进程内存持续增长，不回落
- 系统可用内存持续下降
- 最终导致 OOM（Out of Memory）

### 诊断内存问题的思路

**第一步：查看内存整体情况**
使用 `free` 命令：
- 关注 available，而非 free
- 检查 swap 使用情况
- 评估内存压力程度

**第二步：找出内存消耗者**
按内存使用排序进程：
- 找出占用内存最多的进程
- 判断是否合理
- 检查内存增长趋势

**第三步：分析内存使用细节**
- 使用 pmap 查看进程内存映射
- 区分堆内存、栈内存、共享库
- 识别异常的大块内存分配

**第四步：内存泄漏检测**
- 持续监控进程内存变化
- 使用 valgrind 进行内存泄漏检测
- 分析堆内存分配情况

### 内存优化策略

**调整 swappiness**：
- 默认值 60，表示内核倾向于使用 swap
- 设置为 10，减少 swap 使用，更多使用物理内存
- 数据库等延迟敏感应用建议设置较低值

**使用大页**：
- 普通页 4KB，大页 2MB 或 1GB
- 减少页表项数量，降低 TLB miss
- 适合大内存应用（如数据库）

**定期清理缓存**（谨慎使用）：
- 释放页面缓存和 buffer
- 仅在确定缓存导致问题时使用
- 清理后系统需要重新预热缓存

---

## 磁盘 I/O 分析

### I/O 的关键指标

**吞吐量**：
- **r/s、w/s**：每秒读写次数（IOPS）
- **rkB/s、wkB/s**：每秒读写数据量（带宽）

**延迟**：
- **await**：平均 I/O 等待时间（队列 + 服务时间）
- **svctm**：磁盘平均服务时间（纯处理时间）

**使用率**：
- **%util**：磁盘繁忙程度
- > 80% 表示接近饱和，> 95% 严重瓶颈

**队列长度**：
- **avgqu-sz**：平均请求队列长度
- 队列长表示磁盘处理不过来

### I/O 模式的区别

**顺序 I/O**：
- 连续地址读写
- 机械硬盘性能好（减少寻道时间）
- 适合大文件读写、日志写入

**随机 I/O**：
- 分散地址读写
- 机械硬盘性能差（频繁寻道）
- 数据库典型场景
- SSD 对随机 I/O 友好

### 诊断 I/O 瓶颈的思路

**第一步：判断是否 I/O 瓶颈**
- CPU 的 wa%（iowait）是否高
- 进程是否处于 D 状态（不可中断睡眠）
- 磁盘 %util 是否接近 100%

**第二步：分析 I/O 特征**
- IOPS 高还是带宽高？
  - IOPS 高：小文件随机读写
  - 带宽高：大文件顺序读写
- await 高的原因：
  - await 高、svctm 低：队列排队多，磁盘忙
  - await 高、svctm 高：磁盘本身慢，可能故障

**第三步：找出 I/O 源头**
- 使用 iotop 找出高 I/O 进程
- 分析进程是读密集还是写密集
- 检查进程打开的文件

**第四步：优化方向**
- **应用层**：减少 I/O 次数、批量操作、使用缓存
- **系统层**：调整 I/O 调度器、增大文件系统缓存
- **硬件层**：升级到 SSD、增加磁盘数量（RAID）

### I/O 调度器选择

Linux 支持多种 I/O 调度器，影响 I/O 请求的处理顺序：

**noop**（无操作）：
- 简单的 FIFO 队列
- 适合 SSD 和 NVMe（无需优化寻道）

**deadline**（截止时间）：
- 保证请求在截止时间前完成
- 平衡读写延迟
- 适合数据库等延迟敏感应用

**cfq**（完全公平队列）：
- 为每个进程分配时间片
- 公平但效率较低
- 适合通用服务器

选择建议：
- **SSD/NVMe** → noop 或 deadline
- **机械硬盘 + 数据库** → deadline
- **机械硬盘 + 通用服务器** → cfq

---

## 网络性能分析

### 网络的关键指标

**吞吐量**：
- **RX（Receive）**：接收速率
- **TX（Transmit）**：发送速率
- 是否接近网卡带宽限制

**连接状态**：
- **ESTABLISHED**：正常连接数
- **TIME_WAIT**：等待关闭的连接数
- **CLOSE_WAIT**：应用未关闭的连接数

**延迟与丢包**：
- **RTT**（往返时间）：ping 延迟
- **丢包率**：网络质量指标
- **重传率**：TCP 重传次数

### 诊断网络问题的思路

**第一步：确认网络连通性**
- 使用 ping 测试基本连通性
- 使用 traceroute 追踪路由路径
- 使用 mtr 结合 ping 和 traceroute

**第二步：检查网络带宽**
- 查看接口吞吐量是否接近上限
- 使用 iftop 实时监控流量
- 使用 iperf 测试最大带宽

**第三步：分析连接状态**
- 统计各状态连接数
- TIME_WAIT 过多：短连接频繁，考虑连接池
- CLOSE_WAIT 过多：应用未正确关闭连接
- ESTABLISHED 过多：可能遭受攻击或连接泄漏

**第四步：抓包分析**
- 使用 tcpdump 捕获数据包
- 分析协议握手、重传、延迟
- 使用 Wireshark 图形化分析

### 网络性能优化

**应用层优化**：
- 使用长连接和连接池
- 启用 HTTP Keep-Alive
- 批量发送数据，减少系统调用

**传输层优化**：
- 调整 TCP 缓冲区大小
- 启用 TCP 快速打开（Fast Open）
- 调整拥塞控制算法（如 BBR）

**网络层优化**：
- 调整 MTU 大小
- 减少 TIME_WAIT 超时时间
- 增加本地端口范围

---

## 综合诊断流程

### 快速三板斧

面对性能问题，先用三个命令快速定位：

**1. top**：查看 CPU 和内存
- us% 高 → CPU 计算瓶颈
- wa% 高 → I/O 瓶颈
- Load 高但 CPU 不高 → I/O 等待或过度竞争

**2. free**：查看内存状况
- available < 10% → 内存压力
- Swap 使用持续增加 → 内存不足

**3. iostat**：查看磁盘 I/O
- %util > 80% → 磁盘繁忙
- await > 100ms → I/O 延迟高

### 诊断决策树

```
性能问题
    ↓
查看 top 命令
    ├─ us% > 70% → CPU 计算瓶颈
    │   └─ 使用 perf 找代码热点
    ├─ wa% > 30% → I/O 瓶颈
    │   └─ 使用 iostat 和 iotop
    ├─ sy% > 20% → 系统调用频繁
    │   └─ 使用 strace 分析
    └─ Load 高但 CPU 低 → I/O 等待
        └─ 检查磁盘和网络
```

### 逐层深入

**系统层面**（整体监控）：
- top/htop：快速概览
- vmstat：CPU 和内存统计
- iostat：磁盘 I/O 统计
- ss/netstat：网络连接统计

**进程层面**（资源消耗）：
- ps：进程列表和资源使用
- pidstat：进程级详细统计
- lsof：进程打开的文件和网络连接
- iotop：进程级 I/O 监控

**应用层面**（代码热点）：
- perf：CPU 热点分析
- strace：系统调用跟踪
- valgrind：内存分析
- tcpdump：网络数据包分析

---

## 常见性能问题分析

### 场景 1：系统响应慢

**症状**：应用响应时间长，用户体验差

**诊断步骤**：
1. 查看 Load Average 是否过高
2. 查看 CPU 使用率分布（us、sy、wa）
3. 查看内存 available 是否充足
4. 查看磁盘 %util 是否饱和

**常见原因**：
- CPU 不足：扩容或优化代码
- 内存不足：增加内存或优化内存使用
- 磁盘 I/O 慢：使用 SSD 或优化 I/O 模式
- 网络延迟：检查网络链路或 DNS

### 场景 2：CPU 使用率高

**症状**：top 显示 CPU 接近 100%

**诊断步骤**：
1. 查看是 us% 还是 sy% 高
2. 找出高 CPU 进程
3. 使用 perf 分析进程热点函数
4. 检查是否存在死循环或低效算法

**优化方向**：
- 优化算法，降低时间复杂度
- 使用缓存，避免重复计算
- 多线程并行处理（注意同步开销）
- 水平扩容，增加服务器

### 场景 3：内存持续增长

**症状**：进程内存占用不断上升，不回落

**诊断步骤**：
1. 使用 free 确认系统内存趋势
2. 找出内存持续增长的进程
3. 使用 pmap 查看进程内存分布
4. 使用 valgrind 检测内存泄漏

**常见原因**：
- 内存泄漏：申请后未释放
- 缓存无限增长：未设置大小限制
- 大对象未及时回收：GC 问题（Java 等）

### 场景 4：磁盘 I/O 高

**症状**：系统卡顿，wa% 很高

**诊断步骤**：
1. 查看 iostat 的 %util 和 await
2. 使用 iotop 找出高 I/O 进程
3. 分析是读密集还是写密集
4. 检查是否大量小文件操作

**优化方向**：
- 增加应用缓存，减少磁盘访问
- 批量操作，减少 I/O 次数
- 异步写入，使用 buffer
- 升级到 SSD，提升 IOPS

### 场景 5：网络连接数过多

**症状**：大量 TIME_WAIT 或 ESTABLISHED 连接

**诊断步骤**：
1. 统计各状态连接数
2. 查看是哪个端口的连接
3. 判断是正常流量还是异常

**TIME_WAIT 过多**：
- 原因：短连接频繁建立和关闭
- 优化：使用长连接、连接池
- 调整：减少 TIME_WAIT 超时时间

**CLOSE_WAIT 过多**：
- 原因：应用未正确关闭连接
- 优化：检查代码，确保 close()
- 可能是应用 bug

---

## 核心要点

**性能诊断的本质**：快速定位瓶颈，找到优化方向。

**分层思维**：
- 系统层面：快速定位瓶颈类型（CPU/内存/I/O/网络）
- 进程层面：找出资源消耗者
- 应用层面：优化代码热点

**关联分析**：
- CPU 高 wa% → 磁盘 I/O 瓶颈
- Load 高但 CPU 低 → I/O 等待或锁竞争
- 内存低 + Swap 高 → 内存不足

**工具选择**：
- 快速概览：top、htop
- CPU 分析：vmstat、pidstat、perf
- 内存分析：free、ps、pmap
- 磁盘分析：iostat、iotop
- 网络分析：ss、iftop、tcpdump

**优化原则**:
- 先定位瓶颈，再针对性优化
- 从成本低的优化开始（应用层 → 系统层 → 硬件层）
- 优化后持续监控，验证效果

## 参考资源

- [Linux 性能分析工具 Brendan Gregg](https://www.brendangregg.com/linuxperf.html)
- [USE 方法论](http://www.brendangregg.com/usemethod.html)
- [Linux 性能观测工具速查表](https://www.brendangregg.com/Perf/linux_perf_tools_full.png)
