---
date: 2026-02-03
author: Gaaming Zhang
isOriginal: false
article: true
category:
  - docker
tag:
  - docker
  - ClaudeCode
---

# 容器资源限制

## 为什么需要资源限制？

想象一下这个场景：你的服务器上运行着多个容器应用。突然，其中一个应用出了bug，疯狂消耗内存。几分钟后，整个服务器的内存被耗尽，所有容器都崩溃了——包括那些本来运行正常的应用。

这就是没有资源限制的后果：**一个失控的容器可以拖垮整个系统**。

资源限制的目的是给每个容器设定一个"资源预算"，就像给每个部门分配固定的预算一样。即使某个容器"超支"，也不会影响其他容器。

## 资源限制的底层原理：cgroups

Docker的资源限制功能基于Linux内核的**cgroups（Control Groups）**机制。cgroups可以精确控制进程使用的CPU、内存、磁盘I/O等资源。

你可以把cgroups想象成一个资源管理员，它负责：
- 记录每个容器使用了多少资源
- 当容器使用超出限制时，进行干预（限速或终止）

## CPU限制

### 理解CPU限制的两种方式

**方式1：限制最大使用量**

这是最直观的方式：限制容器最多能用多少CPU。

```bash
# 最多使用1个CPU核心
docker run --cpus=1 myapp

# 最多使用1.5个CPU核心
docker run --cpus=1.5 myapp

# 最多使用0.5个核心（50%）
docker run --cpus=0.5 myapp
```

**方式2：设置相对权重**

当多个容器竞争CPU时，谁能获得更多？权重高的容器获得更多。

```bash
# 默认权重是1024
docker run --cpu-shares=512 low-priority-app   # 权重低，竞争时分配少
docker run --cpu-shares=2048 high-priority-app # 权重高，竞争时分配多
```

**重要区别**：
- `--cpus` 是**硬限制**：即使系统空闲，容器也不能超过这个值
- `--cpu-shares` 是**软限制**：只有在CPU紧张时才生效，空闲时低权重容器也能用满CPU

### 绑定到特定CPU核心

有时候你想让容器只使用特定的CPU核心（比如为了CPU缓存亲和性）：

```bash
# 只使用第0和第1个核心
docker run --cpuset-cpus="0,1" myapp

# 使用0到3号核心
docker run --cpuset-cpus="0-3" myapp
```

## 内存限制

内存限制相比CPU限制更加"严格"——超过CPU限制只是被限速，而**超过内存限制会被直接杀死**（OOM Killer）。

### 基本内存限制

```bash
# 限制内存为512MB
docker run --memory=512m myapp

# 限制内存为2GB
docker run --memory=2g myapp
```

当容器使用的内存超过限制时，Linux的OOM Killer会终止容器内的进程。

### 内存与Swap的关系

除了物理内存，Linux还可以使用磁盘作为"虚拟内存"（Swap）。Docker允许你控制Swap的使用：

```bash
# 内存512MB，内存+Swap总共1GB（即Swap也是512MB）
docker run --memory=512m --memory-swap=1g myapp

# 完全禁用Swap（推荐生产环境使用）
docker run --memory=512m --memory-swap=512m myapp
```

**为什么要禁用Swap？** 当应用开始使用Swap时，性能会急剧下降（磁盘比内存慢10000倍以上）。与其让应用在Swap中苟延残喘，不如让它直接失败，然后快速重启。

### 内存软限制

软限制是一个"目标值"，当系统内存紧张时，Docker会尝试把容器内存压缩到这个值：

```bash
# 硬限制1GB，软限制512MB
docker run --memory=1g --memory-reservation=512m myapp
```

## 磁盘I/O限制

对于I/O密集型应用（如数据库），限制磁盘I/O可以防止一个容器独占磁盘带宽。

### 限制读写速度

```bash
# 限制从/dev/sda读取的速度为10MB/s
docker run --device-read-bps=/dev/sda:10mb myapp

# 限制写入速度为5MB/s
docker run --device-write-bps=/dev/sda:5mb myapp
```

### I/O权重

类似CPU权重，当多个容器竞争磁盘I/O时：

```bash
# 默认权重500，范围10-1000
docker run --blkio-weight=300 low-io-app
docker run --blkio-weight=700 high-io-app
```

## 其他限制

### 进程数限制（防fork炸弹）

```bash
# 限制容器内最多100个进程
docker run --pids-limit=100 myapp
```

这可以防止恶意或失控的进程通过无限fork耗尽系统资源。

### 文件描述符限制

```bash
# 设置最大打开文件数
docker run --ulimit nofile=65535:65535 myapp
```

对于高并发的网络应用（如Nginx、数据库），可能需要增大这个值。

### 共享内存大小

```bash
# 设置/dev/shm大小为256MB（默认64MB）
docker run --shm-size=256m myapp
```

某些应用（如PostgreSQL、Chrome浏览器）需要较大的共享内存。

## 查看资源使用情况

### 实时监控

```bash
# 查看所有容器的资源使用
docker stats

# 查看特定容器
docker stats myapp

# 只显示一次，不持续更新
docker stats --no-stream
```

输出会显示CPU使用率、内存使用量、网络和磁盘I/O等信息。

### 查看容器的资源配置

```bash
docker inspect myapp | grep -A 20 "HostConfig"
```

## 动态调整资源限制

不需要重启容器就可以修改资源限制：

```bash
# 修改内存限制
docker update --memory=1g myapp

# 修改CPU限制
docker update --cpus=2 myapp

# 同时修改多个
docker update --memory=1g --cpus=2 myapp
```

## Docker Compose中的资源限制

在Docker Compose v3（适用于Swarm）中：

```yaml
version: '3.8'
services:
  web:
    image: nginx
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
```

- **limits**：硬限制，不能超过
- **reservations**：预留，保证这个容器至少能获得这么多资源

## 资源限制的最佳实践

### 1. 总是设置内存限制

没有内存限制的容器可能会耗尽整个系统的内存。建议：
- 测试环境先不设限制，观察实际使用量
- 生产环境设置为实际使用量的1.5-2倍
- 禁用Swap：`--memory-swap`等于`--memory`

### 2. 合理设置CPU限制

- 对于Web应用，CPU限制可以稍微宽松
- 对于批处理任务，使用`--cpu-shares`设置较低权重，不影响在线服务

### 3. 监控并调整

资源限制不是设置一次就完事的：
- 监控容器实际资源使用
- OOM频繁发生说明内存限制太低
- CPU被持续限制说明需要更多CPU

### 生产环境示例

```bash
# Web应用
docker run -d \
  --name web \
  --memory=512m \
  --memory-swap=512m \
  --cpus=1 \
  --pids-limit=100 \
  web-app

# 数据库
docker run -d \
  --name postgres \
  --memory=2g \
  --memory-swap=2g \
  --cpus=2 \
  --shm-size=256m \
  postgres:15

# 后台任务（低优先级）
docker run -d \
  --name worker \
  --memory=1g \
  --cpu-shares=256 \
  worker-app
```

## 常见问题

### Q1: 容器被OOM Killer杀死怎么办？

**症状**：容器突然退出，`docker inspect`显示`OOMKilled: true`

**解决方案**：
1. 检查应用是否有内存泄漏
2. 适当增加内存限制
3. 优化应用的内存使用

```bash
# 检查是否因OOM被杀
docker inspect --format='{{.State.OOMKilled}}' myapp
```

### Q2: CPU限制设置后好像不生效？

**可能原因**：
- 使用的是`--cpu-shares`而不是`--cpus`
- `--cpu-shares`只在CPU竞争时生效，空闲时任何容器都可以用满CPU

**解决方案**：使用`--cpus`进行硬限制

### Q3: 如何知道应该设置多少资源限制？

**方法**：
1. 先不设限制，运行一段时间
2. 用`docker stats`观察实际使用量
3. 设置为高峰期使用量的1.5-2倍
4. 持续监控和调整

### Q4: 资源限制会影响性能吗？

cgroups本身的开销很小，几乎可以忽略。但是：
- 内存限制太低会导致频繁OOM
- CPU限制太低会导致应用响应变慢
- I/O限制会直接影响磁盘操作速度

关键是设置**合理**的限制，既防止资源滥用，又不影响正常运行。

## 小结

资源限制是容器化生产部署的必要配置：

- **CPU限制**：`--cpus`硬限制，`--cpu-shares`相对权重
- **内存限制**：`--memory`设置上限，建议同时禁用Swap
- **I/O限制**：控制磁盘读写速度和权重
- **其他限制**：进程数、文件描述符、共享内存等

**核心原则**：
- 宁可稍微宽松，也不要设得太紧导致频繁OOM
- 持续监控，根据实际使用情况调整
- 生产环境必须设置内存限制
