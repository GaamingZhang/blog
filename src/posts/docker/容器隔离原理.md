---
date: 2026-01-26
author: Gaaming Zhang
isOriginal: false
article: true
category:
  - Docker
tag:
  - Docker
  - ClaudeCode
---

# 容器隔离的底层原理

## 隔离的本质问题

想象一个场景：你在同一台服务器上运行了10个容器，它们都认为自己独占了整个系统。这是怎么做到的？

容器本质上只是**宿主机上的普通进程**，但它们"以为"自己独占了：
- 整个文件系统（实际共享宿主机磁盘）
- 所有的网络资源（实际共享宿主机网卡）
- 全部的CPU和内存（实际受到限制）

**这种"欺骗"是如何实现的？** 答案是Linux内核的三大核心技术：
1. **Namespace（命名空间）**：提供视图隔离，让容器"以为"自己独占资源
2. **Cgroups（控制组）**：限制容器能使用多少资源
3. **安全机制**：防止容器逃逸和相互攻击

---

## Namespace：创造独立的"世界观"

### Namespace的核心思想

Namespace就像给进程戴上"VR眼镜"，让它看到一个虚拟的系统环境。

```
真实世界（宿主机）：
├─ 1000个进程
├─ 10个网卡
├─ 100个挂载点

容器的"VR世界"（Namespace）：
├─ 只看到自己的3个进程
├─ 只看到自己的1个网卡
├─ 只看到自己的5个挂载点
```

**关键点**：资源还是那些资源，只是容器看到的视图不同了。

---

## Linux的7种Namespace

### 1. PID Namespace：进程隔离

**隔离的是什么**：进程ID空间

**效果**：容器内的进程树是独立的，容器内的PID 1进程在宿主机上可能是PID 5678。

#### 工作原理

```
宿主机进程视图：
systemd (PID 1)
  ├─ dockerd (PID 1234)
  │   └─ containerd (PID 1235)
  └─ 容器A的nginx (PID 5678)  ← 宿主机看到的PID
      ├─ worker (PID 5679)
      └─ worker (PID 5680)

容器A内的进程视图：
nginx (PID 1)  ← 容器内看到的PID（同一个进程！）
  ├─ worker (PID 6)
  └─ worker (PID 7)
```

**为什么容器内必须是PID 1？**

因为PID Namespace让容器"以为"自己是系统启动的第一个进程。这也是为什么容器的主进程很重要——它负责管理容器内的所有子进程。

#### 隔离的实现

当Docker创建容器时，使用`clone()`系统调用并传入`CLONE_NEWPID`标志：

```c
// 简化的系统调用
clone(child_func, stack, CLONE_NEWPID | SIGCHLD, args);
```

内核会为新进程创建一个全新的PID命名空间，进程在这个空间内的PID从1开始编号。

#### 父子关系的有趣之处

```
容器内：
PID 1 (nginx)
  └─ PID 6 (worker)

宿主机上：
PID 5678 (nginx)
  └─ PID 5679 (worker)
```

同一个父子关系，在不同的Namespace中有不同的PID！

---

### 2. Network Namespace：网络隔离

**隔离的是什么**：网络栈（网卡、IP地址、路由表、iptables规则、端口）

**效果**：每个容器都有独立的网络环境，就像有自己的"虚拟路由器"。

#### 工作原理

```
宿主机网络栈：
┌────────────────────────────┐
│ lo: 127.0.0.1              │
│ eth0: 192.168.1.100        │
│ docker0: 172.17.0.1 (网桥) │
└────────────────────────────┘

容器A的网络栈：
┌────────────────────────────┐
│ lo: 127.0.0.1 (独立的)     │
│ eth0: 172.17.0.2           │
└────────────────────────────┘

容器B的网络栈：
┌────────────────────────────┐
│ lo: 127.0.0.1 (独立的)     │
│ eth0: 172.17.0.3           │
└────────────────────────────┘
```

**关键理解**：
- 每个容器都有自己的127.0.0.1（回环地址）
- 容器访问localhost，访问的是自己的回环接口，不是宿主机的

#### veth pair：连接两个网络世界

容器如何与外界通信？通过一对"虚拟网线"——veth pair。

```
┌─────────────────────┐        ┌──────────────────────┐
│   容器网络空间       │        │   宿主机网络空间      │
│                     │        │                      │
│  eth0 (172.17.0.2) │◄──────►│ vethXXX              │
│  (veth pair一端)   │  虚拟网线│ (veth pair另一端)    │
└─────────────────────┘        │         ↓            │
                               │     docker0          │
                               │      (网桥)          │
                               │         ↓            │
                               │      eth0            │
                               │   (物理网卡)         │
                               └──────────────────────┘
```

**veth pair的特性**：
- 一端在容器内（eth0）
- 另一端在宿主机上（vethXXX）
- 数据从一端进入，从另一端出来
- 就像一根穿过两个世界的"管道"

#### 端口隔离

容器A和容器B可以同时监听80端口，因为它们的端口空间是隔离的：

```
容器A：nginx监听 172.17.0.2:80
容器B：apache监听 172.17.0.3:80
宿主机：不冲突，因为IP不同
```

---

### 3. Mount Namespace：文件系统隔离

**隔离的是什么**：挂载点视图

**效果**：容器内的挂载操作不影响宿主机，每个容器看到不同的文件系统结构。

#### 工作原理

```
宿主机挂载点：
/                      → 宿主机根目录
/var/lib/docker        → Docker数据目录
/home/user             → 用户目录
...（几十个挂载点）

容器挂载点：
/                      → 容器的rootfs（只读层+读写层）
/proc                  → 容器自己的proc
/sys                   → 容器自己的sys
/dev/shm               → 容器自己的共享内存
/data                  → Volume挂载点
```

**关键点**：容器内执行`mount`命令，只能看到自己的挂载点列表。

#### 与UnionFS的配合

Mount Namespace提供"看到什么挂载点"的隔离，UnionFS提供"看到什么文件"的联合视图：

```
容器的文件系统视图：
┌─────────────────────────────┐
│ / (根目录)                   │  ← 通过Mount Namespace隔离
│   ├─ bin/                    │
│   ├─ etc/                    │
│   ├─ app/                    │
│   └─ ...                     │
└─────────────────────────────┘
         ↑
    UnionFS联合挂载
         ↓
┌─────────────────────────────┐
│ 容器层（读写）               │
├─────────────────────────────┤
│ 应用层（只读）               │
├─────────────────────────────┤
│ 依赖层（只读）               │
├─────────────────────────────┤
│ 基础层（只读）               │
└─────────────────────────────┘
```

---

### 4. UTS Namespace：主机名隔离

**隔离的是什么**：主机名和域名

**效果**：每个容器可以有自己的主机名，不会互相影响。

```
宿主机：hostname = "server-prod-01"
容器A：hostname = "web-container"
容器B：hostname = "db-container"
```

**用途**：
- 容器日志中显示容器的主机名，便于识别
- 应用程序可能依赖主机名进行配置
- 微服务架构中，服务发现可能使用主机名

---

### 5. IPC Namespace：进程间通信隔离

**隔离的是什么**：System V IPC和POSIX消息队列、共享内存、信号量

**效果**：容器内的进程无法通过IPC机制与其他容器或宿主机通信。

#### 为什么需要IPC隔离

在Linux中，进程间可以通过以下方式通信：
- **共享内存**：多个进程共享同一块内存区域
- **消息队列**：进程间传递消息
- **信号量**：进程间同步

如果不隔离，恶意容器可能：
- 读取其他容器的共享内存
- 向其他容器的消息队列发送恶意消息
- 干扰其他容器的同步机制

#### 隔离效果

```
宿主机IPC资源：
共享内存段：[shm1, shm2, shm3]
消息队列：[mq1, mq2]
信号量：[sem1, sem2]

容器A的IPC视图：
共享内存段：[shm_containerA]
消息队列：[]
信号量：[]

容器B的IPC视图：
共享内存段：[shm_containerB]
消息队列：[mq_containerB]
信号量：[]
```

---

### 6. User Namespace：用户隔离（最强安全特性）

**隔离的是什么**：用户ID和组ID的映射

**效果**：容器内的root用户可以映射到宿主机的普通用户。

#### 为什么这很重要

默认情况下，容器内的root（UID 0）就是宿主机的root（UID 0）。如果容器逃逸，攻击者就获得了宿主机的root权限！

#### UID映射机制

```
容器内的UID → 映射 → 宿主机的UID

容器内：
root (UID 0)      → 宿主机 UID 100000
user1 (UID 1000)  → 宿主机 UID 101000
user2 (UID 1001)  → 宿主机 UID 101001

映射规则：
container_uid + 100000 = host_uid
```

**安全效果**：
- 容器内的root在宿主机上是UID 100000（普通用户）
- 即使容器逃逸，也无法获得宿主机的真正root权限
- 容器内的进程无法访问宿主机上属于root的文件

#### 配置方法

需要在Docker daemon配置中启用：

```json
{
  "userns-remap": "default"
}
```

Docker会自动创建映射规则：`/etc/subuid`和`/etc/subgid`

---

### 7. Cgroup Namespace：控制组隔离

**隔离的是什么**：Cgroup层次结构的视图

**效果**：容器只能看到自己的Cgroup信息，无法看到宿主机或其他容器的资源限制。

#### 隔离前的问题

在容器内查看`/proc/self/cgroup`，可以看到完整的Cgroup路径：

```
/sys/fs/cgroup/cpu/docker/abc123.../
```

这暴露了：
- 容器ID
- Docker的目录结构
- 宿主机的Cgroup层次

#### 隔离后的效果

容器内看到的Cgroup根目录就是自己的Cgroup：

```
容器内：/sys/fs/cgroup/
宿主机：/sys/fs/cgroup/docker/abc123.../
```

容器"以为"自己的Cgroup就是根Cgroup。

---

## Cgroups：资源限制的执行者

Namespace解决了"看到什么"的问题，Cgroups解决了"能用多少"的问题。

### Cgroups的核心功能

```
隔离（Namespace）：
容器A："我看到100% CPU可用"
容器B："我看到100% CPU可用"

限制（Cgroups）：
容器A："但我只能用50% CPU"
容器B："但我只能用30% CPU"
```

---

## CPU限制的工作原理

### CFS调度器

Linux使用CFS（Completely Fair Scheduler）调度器分配CPU时间。Cgroups通过两个参数控制：

```
cpu.cfs_period_us = 100000   # 周期：100毫秒
cpu.cfs_quota_us  = 50000    # 配额：50毫秒

含义：在每100ms周期内，最多使用50ms CPU时间
效果：相当于0.5个CPU核心
```

### 限制机制

```
时间轴：
├──────┬──────┬──────┬──────┤
0ms   50ms  100ms 150ms 200ms

容器进程：
├─运行─┤暂停├─运行─┤暂停├─...
0-50ms      100-150ms

调度器：
"你的配额用完了，等下个周期吧"
```

**关键点**：
- 不是降低CPU频率，而是限制运行时间
- 超过配额后，进程被挂起，等待下个周期
- 不影响其他容器的CPU使用

---

## 内存限制的工作原理

### 内存Cgroup的层次

```
memory.limit_in_bytes = 536870912  # 硬限制：512MB
memory.soft_limit_in_bytes = 268435456  # 软限制：256MB
memory.oom_control = 0  # 启用OOM killer
```

### 内存使用的三个阶段

```
阶段1：正常使用（< 256MB）
└─ 容器自由使用内存

阶段2：超过软限制（256MB - 512MB）
└─ 内核优先回收此容器的缓存
└─ 影响性能，但不会被杀

阶段3：达到硬限制（512MB）
└─ 触发OOM Killer
└─ 选择容器内某个进程杀掉
└─ 可能导致容器崩溃
```

### OOM Killer的选择算法

当内存超限时，OOM Killer会：

1. 计算每个进程的"oom_score"
2. 选择分数最高的进程杀掉

```
oom_score计算因素：
+ 进程使用的内存量（越大越危险）
+ 进程运行时间（越短越危险）
- oom_score_adj 调整值（可手动设置）
```

**优先被杀的进程**：
- 占用大量内存
- 最近才启动
- 没有root权限

**不会被杀的进程**：
- init进程（PID 1）
- 内核线程

---

## 磁盘I/O限制

### Block I/O Cgroups

```
blkio.throttle.read_bps_device = "8:0 10485760"   # 读：10MB/s
blkio.throttle.write_bps_device = "8:0 10485760"  # 写：10MB/s
```

### 限制机制

```
容器请求写入：
写100MB数据 → blkio检查限制 → 10MB/s
             ↓
实际效果：需要10秒完成
           ↓
多余的I/O请求被排队延迟
```

---

## 安全加固机制

Namespace和Cgroups提供了基础隔离，但还需要额外的安全层。

### 1. Linux Capabilities：细粒度权限控制

传统的root权限是"全有或全无"，Capabilities将root权限拆分成30多个独立的能力。

#### Docker的默认Capabilities

```
默认授予：
CAP_CHOWN          # 修改文件所有者
CAP_DAC_OVERRIDE   # 绕过文件权限检查
CAP_NET_BIND_SERVICE  # 绑定低于1024的端口
CAP_SETUID         # 设置用户ID
CAP_SETGID         # 设置组ID

默认移除（危险）：
CAP_SYS_ADMIN      # 系统管理权限（超级危险）
CAP_NET_ADMIN      # 网络管理
CAP_SYS_MODULE     # 加载内核模块
CAP_SYS_BOOT       # 重启系统
```

#### 最小权限原则

生产环境应该移除所有Capabilities，只保留必需的：

```
移除所有 + 只添加必需的：
--cap-drop=ALL --cap-add=NET_BIND_SERVICE
```

### 2. Seccomp：系统调用过滤

Seccomp限制容器可以使用哪些系统调用。

#### Docker的默认Seccomp Profile

禁止的系统调用包括：
- `mount/umount`：挂载文件系统
- `reboot`：重启系统
- `swapon/swapoff`：交换空间管理
- `create_module/delete_module`：内核模块操作
- `keyctl`：密钥管理

#### 工作原理

```
容器进程尝试：mount("/dev/sda", "/mnt")
         ↓
内核Seccomp过滤器：
"mount系统调用被禁止！"
         ↓
返回错误：EPERM (Operation not permitted)
```

### 3. AppArmor/SELinux：强制访问控制

#### AppArmor（Ubuntu/Debian）

Docker为每个容器生成AppArmor配置文件：

```
/etc/apparmor.d/docker-default:

deny /sys/** w,                # 禁止写入/sys
deny /proc/sys/** w,           # 禁止写入/proc/sys
allow /proc/** r,              # 允许读取/proc
allow /dev/null rw,            # 允许访问/dev/null
```

#### SELinux（RHEL/CentOS）

使用SELinux标签隔离容器：

```
容器进程：svirt_lxc_net_t
容器文件：svirt_sandbox_file_t
宿主机文件：unlabeled_t

SELinux规则：
svirt_lxc_net_t 不能访问 unlabeled_t
```

---

## 容器逃逸与防护

### 常见的逃逸方式

1. **内核漏洞利用**
   - 共享内核是容器的弱点
   - 内核bug可能被用于突破Namespace

2. **特权容器**
   - `--privileged`模式授予所有权限
   - 相当于取消了所有隔离

3. **不当的挂载**
   - 挂载`/var/run/docker.sock`让容器控制Docker
   - 挂载宿主机的敏感目录

4. **Capabilities滥用**
   - `CAP_SYS_ADMIN`几乎等于root
   - 可以执行危险操作

### 防护措施

1. **启用User Namespace**
   - 最有效的防护措施
   - 容器内root映射到宿主机普通用户

2. **最小权限原则**
   - 移除所有不需要的Capabilities
   - 使用严格的Seccomp配置

3. **只读根文件系统**
   - `--read-only`防止恶意修改

4. **定期更新**
   - 及时修复内核漏洞
   - 更新Docker和containerd

5. **不信任容器镜像**
   - 使用官方镜像
   - 扫描镜像漏洞

---

## 总结

Docker容器隔离是一个多层次的防御体系：

**视图隔离（Namespace）**：
- PID：独立的进程空间
- NET：独立的网络栈
- MNT：独立的挂载点
- UTS：独立的主机名
- IPC：独立的进程间通信
- User：UID/GID映射
- Cgroup：独立的资源视图

**资源限制（Cgroups）**：
- CPU：时间片限制
- 内存：硬限制+OOM killer
- 磁盘I/O：带宽限制

**安全加固**：
- Capabilities：细粒度权限
- Seccomp：系统调用过滤
- AppArmor/SELinux：强制访问控制

**关键理解**：
- 容器是"受限的进程"，不是"轻量虚拟机"
- 隔离依赖Linux内核特性，因此共享内核
- 安全性低于虚拟机，但足够用于大多数场景
- 多层防御比单一机制更可靠

容器隔离的本质是**内核级的资源虚拟化**，通过巧妙的设计让每个容器"以为"自己独占系统，实际上所有容器高效地共享底层资源。

## 参考资源

- [Docker 安全官方文档](https://docs.docker.com/engine/security/)
- [Linux Namespace 文档](https://man7.org/linux/man-pages/man7/namespaces.7.html)
- [Cgroups 官方文档](https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt)
