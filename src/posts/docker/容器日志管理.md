---
date: 2026-02-03
author: Gaaming Zhang
isOriginal: false
article: true
category:
  - docker
tag:
  - docker
  - ClaudeCode
---

# 容器日志管理

## 概述

容器日志是运维和排错的重要依据。Docker提供了灵活的日志管理机制，支持多种日志驱动将容器日志输出到不同的目标。本文介绍Docker日志的工作原理、配置方式以及生产环境的日志管理最佳实践。

## 日志工作原理

```
┌─────────────────────────────────────────────────────────────────┐
│                        Container                                 │
│                                                                 │
│  ┌─────────────┐                                               │
│  │ Application │                                               │
│  │             │                                               │
│  │  stdout ────┼──────┐                                       │
│  │  stderr ────┼──────┤                                       │
│  └─────────────┘      │                                       │
│                       │                                        │
└───────────────────────┼────────────────────────────────────────┘
                        │
                        ▼
              ┌─────────────────┐
              │  Docker Engine  │
              │                 │
              │  Logging Driver │
              └────────┬────────┘
                       │
        ┌──────────────┼──────────────┐
        ▼              ▼              ▼
   ┌─────────┐   ┌──────────┐   ┌──────────┐
   │json-file│   │  syslog  │   │ fluentd  │
   │(default)│   │          │   │          │
   └─────────┘   └──────────┘   └──────────┘
```

## 日志驱动类型

| 驱动 | 描述 | 适用场景 |
|------|------|----------|
| **json-file** | 默认驱动，JSON格式写入文件 | 开发、小规模部署 |
| **local** | 优化的本地存储驱动 | 本地开发 |
| **syslog** | 发送到syslog服务 | Linux传统日志系统 |
| **journald** | 发送到systemd journal | systemd系统 |
| **fluentd** | 发送到Fluentd | 日志聚合 |
| **awslogs** | 发送到AWS CloudWatch | AWS环境 |
| **gcplogs** | 发送到Google Cloud Logging | GCP环境 |
| **splunk** | 发送到Splunk | 企业日志分析 |
| **gelf** | 发送GELF格式到Graylog | ELK/Graylog |
| **none** | 禁用日志 | 特殊场景 |

## 基本日志操作

### 查看容器日志

```bash
# 查看日志
docker logs mycontainer

# 跟踪日志输出
docker logs -f mycontainer

# 显示时间戳
docker logs -t mycontainer

# 查看最近n行
docker logs --tail 100 mycontainer

# 查看指定时间后的日志
docker logs --since 2024-01-01T00:00:00 mycontainer
docker logs --since 1h mycontainer   # 最近1小时
docker logs --since 30m mycontainer  # 最近30分钟

# 查看指定时间前的日志
docker logs --until 2024-01-01T12:00:00 mycontainer

# 组合使用
docker logs -f --tail 50 -t mycontainer
docker logs --since 1h --until 30m mycontainer
```

### 日志输出说明

```bash
# Docker将stdout和stderr分开处理
# 可以通过重定向分别获取

# 只看stdout
docker logs mycontainer 2>/dev/null

# 只看stderr
docker logs mycontainer 1>/dev/null

# 导出日志到文件
docker logs mycontainer > app.log 2>&1
```

## json-file驱动（默认）

### 基本配置

```bash
# 运行时指定日志配置
docker run -d \
  --log-driver json-file \
  --log-opt max-size=10m \
  --log-opt max-file=3 \
  myapp
```

### 全局配置

```json
// /etc/docker/daemon.json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "5",
    "compress": "true",
    "labels": "env,app",
    "env": "os,customer"
  }
}
```

```bash
# 重启Docker使配置生效
sudo systemctl restart docker
```

### 日志文件位置

```bash
# 查看容器日志文件位置
docker inspect --format='{{.LogPath}}' mycontainer

# 默认位置
/var/lib/docker/containers/<container-id>/<container-id>-json.log

# 直接查看日志文件（JSON格式）
cat /var/lib/docker/containers/<id>/<id>-json.log | jq

# 日志格式示例
{"log":"Application started\n","stream":"stdout","time":"2024-01-15T10:30:00.123456789Z"}
```

### 日志轮转配置

```json
{
  "log-opts": {
    "max-size": "50m",     // 单个日志文件最大50MB
    "max-file": "10",      // 最多保留10个文件
    "compress": "true"     // 压缩轮转的日志
  }
}
```

## local驱动

local驱动是json-file的优化版本，性能更好。

```json
// /etc/docker/daemon.json
{
  "log-driver": "local",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3",
    "compress": "true"
  }
}
```

**特点**：
- 使用更高效的格式存储
- 自动压缩
- 不支持第三方日志分析工具直接读取

## syslog驱动

```bash
# 发送到本地syslog
docker run -d \
  --log-driver syslog \
  myapp

# 发送到远程syslog
docker run -d \
  --log-driver syslog \
  --log-opt syslog-address=tcp://192.168.1.100:514 \
  --log-opt syslog-facility=daemon \
  --log-opt tag="{{.Name}}/{{.ID}}" \
  myapp
```

```json
// /etc/docker/daemon.json
{
  "log-driver": "syslog",
  "log-opts": {
    "syslog-address": "tcp://192.168.1.100:514",
    "syslog-facility": "daemon",
    "tag": "docker/{{.Name}}"
  }
}
```

## journald驱动

适用于使用systemd的系统。

```bash
# 使用journald驱动
docker run -d \
  --log-driver journald \
  --log-opt tag="myapp" \
  myapp

# 查看日志
journalctl CONTAINER_NAME=mycontainer
journalctl -u docker.service
```

## fluentd驱动

用于将日志发送到Fluentd进行集中处理。

### Fluentd配置

```yaml
# docker-compose.yml
version: '3.8'

services:
  fluentd:
    image: fluent/fluentd:v1.16
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    volumes:
      - ./fluent.conf:/fluentd/etc/fluent.conf

  app:
    image: myapp
    logging:
      driver: fluentd
      options:
        fluentd-address: localhost:24224
        tag: myapp.{{.Name}}
```

```bash
# fluent.conf
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<match **>
  @type file
  path /fluentd/log/container
  <format>
    @type json
  </format>
</match>
```

### 运行时配置

```bash
docker run -d \
  --log-driver fluentd \
  --log-opt fluentd-address=localhost:24224 \
  --log-opt tag="docker.{{.Name}}" \
  --log-opt fluentd-async=true \
  --log-opt fluentd-buffer-limit=8388608 \
  myapp
```

## AWS CloudWatch驱动

```bash
# 使用awslogs驱动
docker run -d \
  --log-driver awslogs \
  --log-opt awslogs-region=us-east-1 \
  --log-opt awslogs-group=myapp-logs \
  --log-opt awslogs-stream=myapp-container \
  --log-opt awslogs-create-group=true \
  myapp
```

```json
// /etc/docker/daemon.json
{
  "log-driver": "awslogs",
  "log-opts": {
    "awslogs-region": "us-east-1",
    "awslogs-group": "docker-logs",
    "awslogs-create-group": "true"
  }
}
```

## gelf驱动（Graylog）

```bash
docker run -d \
  --log-driver gelf \
  --log-opt gelf-address=udp://graylog.example.com:12201 \
  --log-opt tag="myapp" \
  myapp
```

## Docker Compose日志配置

```yaml
version: '3.8'

services:
  web:
    image: nginx
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  api:
    image: myapi
    logging:
      driver: fluentd
      options:
        fluentd-address: fluentd:24224
        tag: api.{{.Name}}

  worker:
    image: worker
    logging:
      driver: none  # 禁用日志

# 全局默认配置
x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"

services:
  app1:
    image: app1
    logging: *default-logging

  app2:
    image: app2
    logging: *default-logging
```

## 日志聚合方案

### EFK（Elasticsearch + Fluentd + Kibana）

```yaml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    volumes:
      - es_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  fluentd:
    build: ./fluentd
    ports:
      - "24224:24224"
    depends_on:
      - elasticsearch

  app:
    image: myapp
    logging:
      driver: fluentd
      options:
        fluentd-address: localhost:24224
        tag: app.{{.Name}}

volumes:
  es_data:
```

### PLG（Promtail + Loki + Grafana）

```yaml
version: '3.8'

services:
  loki:
    image: grafana/loki:2.9.0
    ports:
      - "3100:3100"
    volumes:
      - loki_data:/loki

  promtail:
    image: grafana/promtail:2.9.0
    volumes:
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./promtail-config.yml:/etc/promtail/config.yml
    command: -config.file=/etc/promtail/config.yml

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    depends_on:
      - loki

volumes:
  loki_data:
```

## 日志最佳实践

### 应用日志规范

```dockerfile
# Dockerfile
# 应用应输出到stdout/stderr
CMD ["node", "app.js"]

# 不要
CMD ["node", "app.js > /var/log/app.log 2>&1"]
```

```javascript
// Node.js应用示例
const logger = {
  info: (msg) => console.log(JSON.stringify({ level: 'info', msg, time: new Date().toISOString() })),
  error: (msg) => console.error(JSON.stringify({ level: 'error', msg, time: new Date().toISOString() }))
};
```

### 结构化日志

```python
# Python应用示例
import json
import sys

def log(level, message, **extra):
    entry = {
        'level': level,
        'message': message,
        'timestamp': datetime.utcnow().isoformat(),
        **extra
    }
    print(json.dumps(entry), file=sys.stdout if level != 'error' else sys.stderr)

log('info', 'User logged in', user_id=123, ip='192.168.1.1')
```

### 生产环境配置

```json
// /etc/docker/daemon.json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "50m",
    "max-file": "10",
    "compress": "true",
    "labels": "app,env,version"
  }
}
```

### 日志标签

```bash
# 为容器添加标签，用于日志过滤
docker run -d \
  --label app=web \
  --label env=production \
  --label version=1.0.0 \
  myapp
```

## 实用命令

```bash
# 查看日志
docker logs -f --tail 100 mycontainer

# 查看日志文件位置
docker inspect --format='{{.LogPath}}' mycontainer

# 清空容器日志（谨慎使用）
truncate -s 0 $(docker inspect --format='{{.LogPath}}' mycontainer)

# 查看日志驱动
docker inspect --format='{{.HostConfig.LogConfig.Type}}' mycontainer

# 统计日志大小
du -sh /var/lib/docker/containers/*/

# 查看所有容器日志大小
for container in $(docker ps -qa); do
    echo "$(docker inspect --format='{{.Name}}' $container): $(du -sh $(docker inspect --format='{{.LogPath}}' $container) 2>/dev/null | cut -f1)"
done
```

## 常见问题

### Q1: 日志文件占用过多磁盘空间怎么办？

```bash
# 1. 配置日志轮转
docker run -d \
  --log-opt max-size=10m \
  --log-opt max-file=3 \
  myapp

# 2. 清空现有日志（临时方案）
truncate -s 0 /var/lib/docker/containers/<id>/<id>-json.log

# 3. 全局配置日志限制
# /etc/docker/daemon.json
{
  "log-opts": {
    "max-size": "50m",
    "max-file": "5"
  }
}

# 4. 清理所有容器日志
docker ps -qa | xargs -I {} sh -c 'truncate -s 0 $(docker inspect --format="{{.LogPath}}" {})'
```

### Q2: 使用非json-file驱动后docker logs不可用？

```bash
# 某些日志驱动（如syslog、fluentd）不支持docker logs命令
# 解决方案：

# 1. 使用dual logging（Docker 20.10+）
docker run -d \
  --log-driver local \
  --log-opt dual-logging=true \
  myapp

# 2. 使用json-file + 外部日志收集器
# 让容器使用json-file，使用Filebeat等收集日志
```

### Q3: 如何收集容器内的应用日志文件？

```bash
# 方法1: 使用sidecar容器
# docker-compose.yml
services:
  app:
    image: myapp
    volumes:
      - logs:/var/log/app

  log-shipper:
    image: filebeat
    volumes:
      - logs:/var/log/app:ro
    depends_on:
      - app

volumes:
  logs:

# 方法2: 配置应用输出到stdout
# 大多数情况下推荐这种方式
```

### Q4: 如何根据日志内容触发告警？

```bash
# 使用日志处理工具监控关键词

# 示例：使用shell脚本监控
docker logs -f mycontainer 2>&1 | while read line; do
  if echo "$line" | grep -q "ERROR"; then
    # 发送告警
    curl -X POST https://hooks.slack.com/xxx -d "{\"text\": \"Error detected: $line\"}"
  fi
done

# 生产环境推荐使用专业工具
# - Prometheus + Loki
# - ELK + ElastAlert
# - Fluentd + 自定义插件
```

### Q5: 多容器应用如何统一管理日志？

```yaml
# 使用统一的日志聚合方案
version: '3.8'

x-logging: &logging
  logging:
    driver: fluentd
    options:
      fluentd-address: fluentd:24224
      tag: "{{.Name}}"

services:
  web:
    <<: *logging
    image: nginx

  api:
    <<: *logging
    image: myapi

  worker:
    <<: *logging
    image: worker

  fluentd:
    image: fluent/fluentd
    ports:
      - "24224:24224"
    volumes:
      - ./fluent.conf:/fluentd/etc/fluent.conf
```

## 参考资源

- [Docker 日志官方文档](https://docs.docker.com/config/containers/logging/)
- [日志驱动配置](https://docs.docker.com/config/containers/logging/configure/)
- [日志最佳实践](https://docs.docker.com/config/containers/logging/best-practices/)
