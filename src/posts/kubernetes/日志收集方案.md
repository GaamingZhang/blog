---
date: 2026-02-13
author: Gaaming Zhang
isOriginal: false
article: true
category:
  - Kubernetes
tag:
  - Kubernetes
  - ClaudeCode
---

# Kubernetes日志收集方案：从架构设计到生产实践

日志是故障排查的基石，也是可观测性体系的重要组成部分。在Kubernetes环境中，容器生命周期短暂、节点分散，传统的日志管理方式难以应对。本文将深入探讨Kubernetes日志收集的架构设计、技术选型和生产实践。

---

## 日志架构设计

### 容器日志机制

```
┌─────────────────────────────────────────────────────────────┐
│                    Kubernetes日志流                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  容器应用                                                    │
│  ├── stdout → 标准输出                                       │
│  └── stderr → 标准错误                                       │
│           │                                                 │
│           ▼                                                 │
│  容器运行时（Docker/containerd）                             │
│  ├── 捕获stdout/stderr                                       │
│  ├── 添加容器元数据                                          │
│  └── 写入日志文件                                            │
│           │                                                 │
│           ▼                                                 │
│  节点文件系统                                                │
│  ├── /var/log/containers/<pod>_<namespace>_<container>.log  │
│  ├── /var/log/pods/<namespace>_<pod>_<uid>/<container>.log  │
│  └── /var/lib/docker/containers/<cid>/<cid>-json.log       │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**日志文件格式（JSON）**：

```json
{
  "log": "2024-01-15T10:30:00Z INFO User login successful\n",
  "stream": "stdout",
  "time": "2024-01-15T10:30:00.123456789Z"
}
```

### 三种收集模式对比

```
┌─────────────────────────────────────────────────────────────┐
│                    日志收集模式对比                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  模式一：DaemonSet（节点级代理）                              │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  Node                                                │   │
│  │  ┌──────────┐ ┌──────────┐ ┌──────────┐            │   │
│  │  │ Pod A    │ │ Pod B    │ │ Pod C    │            │   │
│  │  └────┬─────┘ └────┬─────┘ └────┬─────┘            │   │
│  │       │            │            │                   │   │
│  │       └────────────┼────────────┘                   │   │
│  │                    ▼                                │   │
│  │            ┌──────────────┐                        │   │
│  │            │  Log Agent   │                        │   │
│  │            │  (DaemonSet) │                        │   │
│  │            └──────────────┘                        │   │
│  └─────────────────────────────────────────────────────┘   │
│  优点：资源效率高、运维简单                                   │
│  缺点：所有应用共享配置                                       │
│                                                             │
│  模式二：Sidecar                                            │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  Pod                                                 │   │
│  │  ┌──────────┐      ┌──────────┐                     │   │
│  │  │ App      │─log─►│ Sidecar  │                     │   │
│  │  │ Container│ file │  Agent   │                     │   │
│  │  └──────────┘      └──────────┘                     │   │
│  └─────────────────────────────────────────────────────┘   │
│  优点：灵活定制、应用隔离                                     │
│  缺点：资源开销大、配置复杂                                   │
│                                                             │
│  模式三：直接推送                                            │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  App Container                                       │   │
│  │  ┌──────────────────────────────────────────────┐  │   │
│  │  │  Application Code                             │  │   │
│  │  │  └──► Log SDK ──► Log Backend (HTTP/gRPC)    │  │   │
│  │  └──────────────────────────────────────────────┘  │   │
│  └─────────────────────────────────────────────────────┘   │
│  优点：无额外组件、实时性好                                   │
│  缺点：应用耦合、增加代码复杂度                               │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**选型建议**：

| 场景 | 推荐模式 | 理由 |
| ---- | -------- | ---- |
| 通用场景 | DaemonSet | 资源效率高、运维简单 |
| 多租户环境 | Sidecar | 租户隔离、配置独立 |
| 特殊日志格式 | Sidecar | 定制解析规则 |
| 高实时性要求 | 直接推送 | 减少中间环节 |

---

## Fluent Bit实战

### 架构设计

```
┌─────────────────────────────────────────────────────────────┐
│                    Fluent Bit架构                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Input → Parser → Filter → Output                          │
│                                                             │
│  Input插件：                                                 │
│  ├── tail：读取日志文件                                      │
│  ├── systemd：读取systemd日志                                │
│  └── forward：接收远程日志                                   │
│                                                             │
│  Filter插件：                                                │
│  ├── kubernetes：添加K8s元数据                               │
│  ├── grep：过滤日志                                          │
│  ├── modify：修改字段                                        │
│  └── lua：自定义处理逻辑                                     │
│                                                             │
│  Output插件：                                                │
│  ├── elasticsearch：发送到ES                                 │
│  ├── loki：发送到Loki                                        │
│  ├── kafka：发送到Kafka                                      │
│  └── file：写入本地文件                                       │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### DaemonSet部署

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: logging
  labels:
    app: fluent-bit
spec:
  selector:
    matchLabels:
      app: fluent-bit
  template:
    metadata:
      labels:
        app: fluent-bit
    spec:
      serviceAccountName: fluent-bit
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: fluent-bit
        image: fluent/fluent-bit:2.1
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 2020
          name: metrics
        volumeMounts:
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config
          mountPath: /fluent-bit/etc/
        resources:
          limits:
            cpu: 500m
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 50Mi
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config
        configMap:
          name: fluent-bit-config
```

### 配置文件详解

```ini
# fluent-bit-configmap.yaml
[SERVICE]
    Flush         5
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf
    HTTP_Server   On
    HTTP_Listen   0.0.0.0
    HTTP_Port     2020

[INPUT]
    Name              tail
    Tag               kube.*
    Path              /var/log/containers/*.log
    Parser            docker
    DB                /var/log/flb_kube.db
    Mem_Buf_Limit     10MB
    Skip_Long_Lines   On
    Refresh_Interval  10

[FILTER]
    Name                kubernetes
    Match               kube.*
    Kube_URL            https://kubernetes.default.svc:443
    Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
    Kube_Tag_Prefix     kube.var.log.containers.
    Merge_Log           On
    Merge_Log_Key       log_processed
    K8S-Logging.Parser  On
    K8S-Logging.Exclude On

[FILTER]
    Name    modify
    Match   kube.*
    Add     cluster_name production
    Add     environment prod

[OUTPUT]
    Name            elasticsearch
    Match           kube.*
    Host            elasticsearch.logging.svc.cluster.local
    Port            9200
    Logstash_Format On
    Logstash_Prefix k8s-logs
    Time_Key        @timestamp
    Replace_Dots    On
    Retry_Limit     False
    tls             On
    tls.verify      Off
```

### 自定义Parser

```ini
# parsers.conf
[PARSER]
    Name        docker
    Format      json
    Time_Key    time
    Time_Format %Y-%m-%dT%H:%M:%S.%L
    Time_Keep   On

[PARSER]
    Name        nginx
    Format      regex
    Regex       ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
    Time_Key    time
    Time_Format %d/%b/%Y:%H:%M:%S %z

[PARSER]
    Name        json
    Format      json
    Time_Key    timestamp
    Time_Format %Y-%m-%dT%H:%M:%S.%LZ

[PARSER]
    Name        java-multiline
    Format      regex
    Regex       ^(?<time>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2},\d{3}) \[(?<thread>.*)\] (?<level>[^\s]+)\s+(?<class>\S+) - (?<message>.*)$
    Time_Key    time
    Time_Format %Y-%m-%d %H:%M:%S,%L
```

---

## Loki实战

### Loki架构

```
┌─────────────────────────────────────────────────────────────┐
│                    Loki架构                                  │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────┐                                            │
│  │  Promtail   │  日志采集、标签提取                          │
│  │  (DaemonSet)│                                            │
│  └──────┬──────┘                                            │
│         │                                                   │
│         ▼                                                   │
│  ┌─────────────┐                                            │
│  │    Loki     │  日志存储、查询处理                          │
│  │  ┌─────────┐│                                            │
│  │  │Distributor││  接收日志、分发到Ingester                  │
│  │  ├─────────┤│                                            │
│  │  │Ingester  ││  写入日志、构建索引                         │
│  │  ├─────────┤│                                            │
│  │  │Querier   ││  处理查询请求                               │
│  │  └─────────┘│                                            │
│  └──────┬──────┘                                            │
│         │                                                   │
│         ▼                                                   │
│  ┌─────────────┐                                            │
│  │   Grafana   │  可视化查询界面                              │
│  └─────────────┘                                            │
│                                                             │
│  存储后端：                                                  │
│  ├── 单机：文件系统                                          │
│  └── 分布式：S3/GCS/Azure Blob + Cassandra/DynamoDB         │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### Promtail配置

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: logging
data:
  promtail.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0

    positions:
      filename: /tmp/positions.yaml

    clients:
      - url: http://loki.logging.svc:3100/loki/api/v1/push
        tenant_id: production

    scrape_configs:
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
        - role: pod
      pipeline_stages:
        - docker: {}
        - match:
            selector: '{app="nginx"}'
            stages:
            - regex:
                expression: '^(?P<remote>[^ ]*) - (?P<user>[^ ]*) \[(?P<time>[^\]]*)\] "(?P<method>\S+) (?P<path>[^ ]*) (?P<protocol>[^"]*)" (?P<status>\d+) (?P<size>\d+)'
            - labels:
                method:
                status:
      relabel_configs:
        - source_labels: [__meta_kubernetes_pod_label_app]
          target_label: app
        - source_labels: [__meta_kubernetes_namespace]
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          target_label: pod
        - source_labels: [__meta_kubernetes_pod_container_name]
          target_label: container
```

### LogQL查询语法

```
# 基本查询：按标签过滤
{namespace="production", app="nginx"}

# 多标签匹配
{namespace="production", app=~"nginx|api"}

# 行过滤
{namespace="production"} |= "error"

# 正则过滤
{namespace="production"} |~ "error|exception"

# JSON解析
{namespace="production"} | json | level="error"

# 聚合查询：错误日志数量
sum by (app) (count_over_time({namespace="production"} |= "error" [1h]))

# 延迟分布
histogram_quantile(0.99, 
  sum by (le) (rate({app="nginx"} 
    | regexp "duration=(?P<duration>\\d+)" 
    | __error__="" [5m]))
)
```

---

## Elasticsearch实战

### 索引设计

```
┌─────────────────────────────────────────────────────────────┐
│                    Elasticsearch索引策略                     │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  按时间滚动索引：                                            │
│  ├── k8s-logs-2024.01.15                                    │
│  ├── k8s-logs-2024.01.16                                    │
│  └── k8s-logs-2024.01.17                                    │
│                                                             │
│  索引模板配置：                                              │
│  ├── 主分片数：根据数据量和节点数                             │
│  ├── 副本数：生产环境至少1个                                  │
│  ├── 映射：关键字段设置合适类型                               │
│  └── 生命周期：自动滚动、删除                                 │
│                                                             │
│  分片规划：                                                  │
│  ├── 每个分片：10-50GB                                       │
│  ├── 分片数 ≤ 节点数 × 20                                    │
│  └── 热数据节点：SSD存储                                      │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### ILM生命周期管理

```json
PUT _ilm/policy/k8s-logs-policy
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_size": "50GB",
            "max_age": "1d"
          },
          "set_priority": {
            "priority": 100
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "shrink": {
            "number_of_shards": 1
          },
          "forcemerge": {
            "max_num_segments": 1
          },
          "allocate": {
            "require": {
              "data_type": "warm"
            }
          },
          "set_priority": {
            "priority": 50
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "freeze": {},
          "allocate": {
            "require": {
              "data_type": "cold"
            }
          },
          "set_priority": {
            "priority": 0
          }
        }
      },
      "delete": {
        "min_age": "90d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
```

### 索引模板

```json
PUT _index_template/k8s-logs-template
{
  "index_patterns": ["k8s-logs-*"],
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "index.lifecycle.name": "k8s-logs-policy",
      "index.lifecycle.rollover_alias": "k8s-logs"
    },
    "mappings": {
      "properties": {
        "@timestamp": { "type": "date" },
        "kubernetes": {
          "properties": {
            "namespace_name": { "type": "keyword" },
            "pod_name": { "type": "keyword" },
            "container_name": { "type": "keyword" },
            "labels": { "type": "object", "enabled": true }
          }
        },
        "log": {
          "type": "text",
          "fields": {
            "keyword": { "type": "keyword", "ignore_above": 256 }
          }
        },
        "level": { "type": "keyword" },
        "message": { "type": "text" }
      }
    }
  }
}
```

---

## 日志规范化实践

### 结构化日志标准

```json
{
  "timestamp": "2024-01-15T10:30:00.123Z",
  "level": "INFO",
  "service": "user-api",
  "trace_id": "abc123def456",
  "span_id": "span789",
  "user_id": "12345",
  "request_id": "req-xyz",
  "message": "User login successful",
  "context": {
    "ip": "192.168.1.100",
    "user_agent": "Mozilla/5.0",
    "duration_ms": 45
  },
  "error": null
}
```

**字段规范**：

| 字段 | 类型 | 必需 | 说明 |
| ---- | ---- | ---- | ---- |
| timestamp | ISO8601 | 是 | UTC时间戳 |
| level | string | 是 | DEBUG/INFO/WARN/ERROR |
| service | string | 是 | 服务名称 |
| trace_id | string | 推荐 | 分布式追踪ID |
| message | string | 是 | 日志消息 |
| context | object | 否 | 上下文信息 |
| error | object | 否 | 错误详情 |

### 应用日志配置

**Go应用示例**：

```go
import (
    "go.uber.org/zap"
    "go.uber.org/zap/zapcore"
)

func NewLogger(serviceName string) *zap.Logger {
    config := zap.Config{
        Level:       zap.NewAtomicLevelAt(zapcore.InfoLevel),
        Development: false,
        Encoding:    "json",
        EncoderConfig: zapcore.EncoderConfig{
            TimeKey:        "timestamp",
            LevelKey:       "level",
            NameKey:        "logger",
            CallerKey:      "caller",
            MessageKey:     "message",
            StacktraceKey:  "stacktrace",
            LineEnding:     zapcore.DefaultLineEnding,
            EncodeLevel:    zapcore.LowercaseLevelEncoder,
            EncodeTime:     zapcore.ISO8601TimeEncoder,
            EncodeDuration: zapcore.SecondsDurationEncoder,
            EncodeCaller:   zapcore.ShortCallerEncoder,
        },
        OutputPaths:      []string{"stdout"},
        ErrorOutputPaths: []string{"stderr"},
        InitialFields: map[string]interface{}{
            "service": serviceName,
        },
    }
    
    logger, _ := config.Build()
    return logger
}

// 使用示例
logger.Info("User login successful",
    zap.String("user_id", "12345"),
    zap.String("trace_id", traceID),
    zap.Duration("duration", duration),
)
```

**Java应用示例（Logback）**：

```xml
<configuration>
    <appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <includeMdcKeyName>trace_id</includeMdcKeyName>
            <includeMdcKeyName>span_id</includeMdcKeyName>
            <includeMdcKeyName>user_id</includeMdcKeyName>
            <fieldNames>
                <timestamp>timestamp</timestamp>
                <level>level</level>
                <logger>logger</logger>
                <message>message</message>
                <stackTrace>stack_trace</stackTrace>
            </fieldNames>
        </encoder>
    </appender>
    
    <root level="INFO">
        <appender-ref ref="JSON"/>
    </root>
</configuration>
```

---

## 日志告警配置

### Loki告警规则

```yaml
groups:
- name: log-alerts
  rules:
  - alert: HighErrorRate
    expr: |
      sum by (app) (count_over_time({namespace="production"} |= "error" [5m]))
      / sum by (app) (count_over_time({namespace="production"} [5m])) > 0.05
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "应用错误率过高"
      description: "应用 {{ $labels.app }} 错误率 {{ $value | printf \"%.2f\" }}"

  - alert: ApplicationCrash
    expr: |
      count_over_time({namespace="production"} |= "panic" or |= "fatal" [5m]) > 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "应用发生崩溃"
      description: "检测到panic或fatal错误"

  - alert: DatabaseConnectionFailed
    expr: |
      count_over_time({namespace="production"} |~ "connection.*refused|database.*error" [5m]) > 10
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "数据库连接失败"
      description: "检测到大量数据库连接错误"
```

### Elasticsearch告警（通过Kibana）

```json
POST _watcher/watch/error_rate_watch
{
  "trigger": {
    "schedule": {
      "interval": "5m"
    }
  },
  "input": {
    "search": {
      "request": {
        "indices": ["k8s-logs-*"],
        "body": {
          "query": {
            "bool": {
              "must": [
                { "range": { "@timestamp": { "gte": "now-5m" } } },
                { "term": { "level": "error" } }
              ]
            }
          },
          "aggs": {
            "by_app": {
              "terms": { "field": "kubernetes.labels.app.keyword" }
            }
          }
        }
      }
    }
  },
  "condition": {
    "compare": {
      "ctx.payload.hits.total": {
        "gt": 100
      }
    }
  },
  "actions": {
    "send_email": {
      "email": {
        "to": "ops@example.com",
        "subject": "High Error Rate Alert",
        "body": "Detected {{ctx.payload.hits.total}} errors in the last 5 minutes"
      }
    }
  }
}
```

---

## 常见问题与解答

### 1. 日志丢失怎么排查？

**排查步骤**：

```bash
# 1. 检查日志收集器状态
kubectl get pods -n logging -l app=fluent-bit

# 2. 检查日志收集器日志
kubectl logs -n logging -l app=fluent-bit --tail=100

# 3. 检查节点日志文件是否存在
kubectl exec -n logging fluent-bit-xxxxx -- ls -la /var/log/containers/

# 4. 检查Fluent Bit指标
kubectl port-forward -n logging svc/fluent-bit 2020:2020
curl http://localhost:2020/api/v1/metrics
```

**常见原因**：

| 原因 | 解决方案 |
| ---- | -------- |
| Pod已删除 | 使用集中日志系统 |
| 磁盘空间满 | 配置日志轮转 |
| 收集器崩溃 | 检查资源限制 |
| 网络问题 | 检查输出端点连通性 |

### 2. 如何处理大日志量？

**优化策略**：

```
1. 日志源头优化
   ├── 调整日志级别（生产用INFO）
   ├── 过滤健康检查日志
   └── 使用采样（高频日志）

2. 传输层优化
   ├── 压缩传输（gzip）
   ├── 批量发送
   └── 本地缓冲

3. 存储层优化
   ├── 冷热分离
   ├── 索引优化
   └── 生命周期管理
```

### 3. EFK vs PLG 如何选择？

**对比分析**：

| 维度 | EFK | PLG |
| ---- | --- | --- |
| 搜索能力 | 强（全文索引） | 弱（标签过滤） |
| 资源消耗 | 高 | 低 |
| 运维复杂度 | 高 | 低 |
| 学习曲线 | 陡峭 | 平缓 |
| 适用规模 | 大型 | 中小型 |
| 成本 | 高 | 低 |

**选择建议**：

- 已有Grafana生态 → PLG
- 需要复杂搜索 → EFK
- 资源有限 → PLG
- 日志量>1TB/天 → EFK

### 4. 如何实现跨服务的日志追踪？

**TraceID传播**：

```go
// HTTP中间件
func TraceMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        traceID := r.Header.Get("X-Trace-ID")
        if traceID == "" {
            traceID = uuid.New().String()
        }
        
        ctx := context.WithValue(r.Context(), "trace_id", traceID)
        r = r.WithContext(ctx)
        
        w.Header().Set("X-Trace-ID", traceID)
        next.ServeHTTP(w, r)
    })
}

// 日志记录
func LogWithContext(ctx context.Context, message string) {
    traceID := ctx.Value("trace_id").(string)
    logger.Info(message, zap.String("trace_id", traceID))
}

// 下游调用时传递
req.Header.Set("X-Trace-ID", traceID)
```

### 5. 如何处理多行日志？

**Java堆栈跟踪示例**：

```ini
# Fluent Bit多行解析器
[MULTILINE_PARSER]
    Name          java-multiline
    Type          regex
    Flush_Timeout 1000
    Rule      "start_state"  "/^\d{4}-\d{1,2}-\d{1,2}/"  "cont"
    Rule      "cont"         "/^\s+at.*/"               "cont"
    Rule      "cont"         "/^\s+... \d+ more/"       "cont"
    Rule      "cont"         "/^\s*Caused by:.*/"       "cont"
```

**Fluentd多行配置**：

```xml
<filter kubernetes.**>
  type parser
  key_name log
  format multiline
  format_firstline /^\d{4}-\d{1,2}-\d{1,2}/
  format1 /^(?<time>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2},\d{3}) \[(?<thread>.*)\] (?<level>[^\s]+)\s+(?<class>\S+) - (?<message>.*)/
</filter>```

## 参考资源

- [Kubernetes 日志架构官方文档](https://kubernetes.io/docs/concepts/cluster-administration/logging/)
- [Fluent Bit 官方文档](https://docs.fluentbit.io/manual/)
- [Grafana Loki 文档](https://grafana.com/docs/loki/latest/)
