---
date: 2026-01-24
author: Gaaming Zhang
isOriginal: true
article: true
category:
  - Kubernetes
tag:
  - Kubernetes
  - ClaudeCode
---

# Kubernetes的探针机制

## 概述

在Kubernetes集群中,探针(Probe)是一种用于检测容器健康状态的机制。通过探针,Kubernetes能够自动发现应用的健康状况,并在必要时采取相应的措施,如重启不健康的容器或停止向其发送流量。这是实现应用高可用性和自愈能力的关键特性之一。

探针机制让Kubernetes不仅能管理容器的生命周期,还能深入了解容器内应用的实际运行状态。这种能力使得Kubernetes能够做出更智能的调度和流量管理决策,从而提高整个集群的稳定性和可靠性。

## 探针的类型

Kubernetes提供了三种类型的探针,每种探针服务于不同的目的:

### 1. 存活探针(Liveness Probe)

存活探针用于检测容器是否正在运行。如果存活探针失败,kubelet会杀死容器,并根据重启策略决定是否重启容器。存活探针主要用于捕获死锁、无限循环或应用进入不可恢复状态等情况。

**使用场景:**
- 应用可能陷入死锁但进程仍在运行
- 应用内部发生严重错误,无法自行恢复
- 长时间运行的应用可能出现内存泄漏或资源耗尽

**注意事项:**
- 不要将存活探针设置得过于敏感,否则可能导致容器频繁重启
- 探针的超时时间应考虑应用的实际响应时间
- 对于启动缓慢的应用,应配合启动探针使用

### 2. 就绪探针(Readiness Probe)

就绪探针用于检测容器是否准备好接收流量。如果就绪探针失败,端点控制器会将Pod的IP地址从所有匹配的Service的端点列表中移除。在初始延迟之前,就绪探针的默认状态是失败。

**使用场景:**
- 应用需要加载大量数据或配置才能提供服务
- 应用依赖外部服务,需要等待外部服务可用
- 应用需要预热或缓存初始化
- 应用需要临时拒绝流量进行内部维护

**注意事项:**
- 就绪探针失败不会导致容器重启,只是暂时不接收流量
- 适合用于处理临时性的不可用状态
- 可以在应用运行期间动态改变就绪状态

### 3. 启动探针(Startup Probe)

启动探针用于检测容器内的应用是否已经启动。如果配置了启动探针,在启动探针成功之前,其他所有探针都会被禁用。如果启动探针失败,kubelet会杀死容器,容器会根据重启策略进行处理。

**使用场景:**
- 应用启动时间较长,需要较长时间才能准备就绪
- 遗留应用或需要额外初始化时间的应用
- 避免慢启动应用被存活探针过早杀死

**注意事项:**
- 启动探针只在容器启动时执行,成功后不再执行
- 可以设置较长的失败阈值以适应慢启动应用
- 一旦启动探针成功,存活探针和就绪探针才会接管

## 探针的检测方式

Kubernetes支持四种探针处理器(Handler),用于执行实际的健康检查:

### 1. ExecAction

通过在容器内执行指定的命令来检查健康状态。如果命令退出时返回码为0,则认为探测成功,否则认为失败。

**优点:**
- 灵活性高,可以执行任何自定义检查逻辑
- 适合复杂的健康检查场景
- 可以检查文件系统、数据库连接等

**缺点:**
- 每次探测都需要创建新进程,开销较大
- 需要在容器内安装必要的工具和脚本
- 调试相对复杂

**示例配置:**

```yaml
livenessProbe:
  exec:
    command:
    - cat
    - /tmp/healthy
  initialDelaySeconds: 5
  periodSeconds: 5
```

### 2. TCPSocketAction

通过尝试与容器的指定端口建立TCP连接来检查健康状态。如果能够成功建立连接,则认为探测成功。

**优点:**
- 轻量级,开销小
- 适合检查服务端口是否可用
- 不需要容器内的额外工具

**缺点:**
- 只能检查端口是否开放,无法验证应用逻辑
- 某些应用可能接受连接但无法正常服务
- 无法检测应用层的错误

**示例配置:**

```yaml
livenessProbe:
  tcpSocket:
    port: 8080
  initialDelaySeconds: 15
  periodSeconds: 10
```

### 3. HTTPGetAction

通过向容器的指定端口和路径发送HTTP GET请求来检查健康状态。如果响应的状态码大于等于200且小于400,则认为探测成功。

**优点:**
- 适合Web应用和HTTP服务
- 可以自定义健康检查端点
- 支持HTTP头和scheme配置

**缺点:**
- 仅适用于HTTP服务
- 需要应用实现健康检查端点
- 网络开销相对较大

**示例配置:**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
    httpHeaders:
    - name: Custom-Header
      value: Awesome
  initialDelaySeconds: 3
  periodSeconds: 3
```

### 4. gRPC

通过gRPC健康检查协议来检查健康状态。容器必须实现gRPC健康检查协议。

**优点:**
- 原生支持gRPC服务
- 性能优于HTTP探针
- 类型安全

**缺点:**
- 仅适用于gRPC服务
- 需要应用实现gRPC健康检查服务
- 相对较新,支持版本要求较高(Kubernetes 1.24+)

**示例配置:**

```yaml
livenessProbe:
  grpc:
    port: 9090
  initialDelaySeconds: 5
  periodSeconds: 10
```

## 探针配置参数详解

探针支持多个配置参数,用于精细控制探测行为:

### initialDelaySeconds

容器启动后第一次执行探测需要等待的时间,单位为秒。默认值为0,最小值为0。这个参数对于需要一定启动时间的应用非常重要。

```yaml
initialDelaySeconds: 30
```

### periodSeconds

执行探测的频率,单位为秒。默认值为10秒,最小值为1秒。这个值决定了多久执行一次健康检查。

```yaml
periodSeconds: 10
```

### timeoutSeconds

探测超时时间,单位为秒。默认值为1秒,最小值为1秒。如果探测在此时间内没有响应,则认为探测失败。

```yaml
timeoutSeconds: 5
```

### successThreshold

探测失败后,被视为成功的最小连续成功次数。默认值为1,最小值为1。对于存活探针和启动探针,此值必须为1。

```yaml
successThreshold: 1
```

### failureThreshold

探测成功后,被视为失败的最小连续失败次数。默认值为3,最小值为1。达到此阈值后,Kubernetes会采取相应的措施。

```yaml
failureThreshold: 3
```

### terminationGracePeriodSeconds

可选参数,用于为探针失败时的Pod终止提供特定的宽限期,而不使用Pod级别的terminationGracePeriodSeconds。

```yaml
terminationGracePeriodSeconds: 60
```

## 完整的探针配置示例

下面是一个综合使用三种探针的完整配置示例:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: probe-demo
  labels:
    app: probe-demo
spec:
  containers:
  - name: app
    image: myapp:latest
    ports:
    - containerPort: 8080
    
    # 启动探针 - 用于慢启动应用
    startupProbe:
      httpGet:
        path: /startup
        port: 8080
      initialDelaySeconds: 0
      periodSeconds: 10
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 30  # 最多等待300秒(30*10)
    
    # 存活探针 - 检测应用是否存活
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
        httpHeaders:
        - name: X-Custom-Header
          value: ProbeCheck
      initialDelaySeconds: 15
      periodSeconds: 20
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 3
    
    # 就绪探针 - 检测应用是否准备接收流量
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 3
```

## 探针使用的最佳实践

### 1. 合理配置探针参数

探针的配置参数应该根据应用的实际情况来设置,避免使用默认值:

- **initialDelaySeconds**: 应该大于应用的平均启动时间,但对于慢启动应用,建议使用启动探针
- **periodSeconds**: 不宜过短,避免给应用带来额外负担;也不宜过长,否则无法及时发现问题
- **timeoutSeconds**: 应该考虑网络延迟和应用的响应时间
- **failureThreshold**: 不宜设置为1,给应用一些容错空间

### 2. 区分存活探针和就绪探针的用途

存活探针和就绪探针的目的不同,不应该使用相同的检查逻辑:

- **存活探针**: 检查应用是否陷入死锁或不可恢复状态,应该轻量级,避免检查外部依赖
- **就绪探针**: 检查应用是否准备好处理请求,可以检查外部依赖的可用性

错误示例:

```yaml
# 不推荐: 存活探针检查数据库连接
livenessProbe:
  exec:
    command:
    - sh
    - -c
    - "pg_isready -h localhost -U user"
```

如果数据库暂时不可用,这会导致容器被不必要地重启。应该只在就绪探针中检查数据库连接。

### 3. 使用启动探针处理慢启动应用

对于启动时间较长的应用,不要简单地增加存活探针的initialDelaySeconds,而应该使用启动探针:

```yaml
startupProbe:
  httpGet:
    path: /healthz
    port: 8080
  failureThreshold: 30  # 30 * 10 = 300秒
  periodSeconds: 10

livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  periodSeconds: 10
  failureThreshold: 3
```

这样,应用有足够的时间启动,启动后又能快速检测到问题。

### 4. 健康检查端点应该轻量级

健康检查端点会被频繁调用,应该尽可能轻量级:

- 避免执行耗时的操作
- 避免进行复杂的业务逻辑检查
- 可以使用缓存来减少对外部依赖的检查频率
- 设置合理的超时时间

```go
// 使用缓存减少数据库检查频率
type CachedHealthChecker struct {
    lastCheck     time.Time
    lastResult    bool
    cacheDuration time.Duration
    mu            sync.RWMutex
}

func (c *CachedHealthChecker) CheckDatabase() bool {
    c.mu.RLock()
    if time.Since(c.lastCheck) < c.cacheDuration {
        result := c.lastResult
        c.mu.RUnlock()
        return result
    }
    c.mu.RUnlock()
    
    c.mu.Lock()
    defer c.mu.Unlock()
    
    // 再次检查,防止并发时重复执行
    if time.Since(c.lastCheck) < c.cacheDuration {
        return c.lastResult
    }
    
    // 执行实际的数据库检查
    result := actualDatabaseCheck()
    c.lastCheck = time.Now()
    c.lastResult = result
    return result
}

func actualDatabaseCheck() bool {
    // 实际的数据库检查逻辑
    return true
}
```

### 5. 避免探针误杀

探针配置不当可能导致健康的容器被误杀:

- 不要将failureThreshold设置为1
- 确保timeoutSeconds足够长,考虑网络波动和短暂的高负载
- 对于可能有瞬时高负载的应用,适当增加periodSeconds
- 存活探针不应该检查外部依赖

### 6. 使用专用的健康检查端口

可以考虑使用独立的端口提供健康检查服务,与业务流量分离:

```go
func main() {
    // 业务服务
    go func() {
        http.HandleFunc("/api", apiHandler)
        log.Fatal(http.ListenAndServe(":8080", nil))
    }()
    
    // 健康检查服务
    healthMux := http.NewServeMux()
    healthMux.HandleFunc("/healthz", healthzHandler)
    healthMux.HandleFunc("/ready", readyHandler)
    log.Fatal(http.ListenAndServe(":8081", healthMux))
}
```

配置探针时使用健康检查端口:

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8081  # 健康检查专用端口
```

### 7. 监控探针失败情况

应该监控探针的失败情况,及时发现配置问题或应用问题:

- 使用Prometheus等工具收集探针失败指标
- 设置告警规则,在探针频繁失败时发出告警
- 分析探针失败的模式,优化配置或修复应用问题

### 8. 在CI/CD中测试健康检查端点

将健康检查端点的测试集成到CI/CD流程中:

```go
// health_test.go
package main

import (
    "net/http"
    "net/http/httptest"
    "testing"
)

func TestHealthzEndpoint(t *testing.T) {
    req, err := http.NewRequest("GET", "/healthz", nil)
    if err != nil {
        t.Fatal(err)
    }
    
    rr := httptest.NewRecorder()
    handler := http.HandlerFunc(healthzHandler)
    handler.ServeHTTP(rr, req)
    
    if status := rr.Code; status != http.StatusOK {
        t.Errorf("handler returned wrong status code: got %v want %v",
            status, http.StatusOK)
    }
}

func TestReadyEndpoint(t *testing.T) {
    req, err := http.NewRequest("GET", "/ready", nil)
    if err != nil {
        t.Fatal(err)
    }
    
    rr := httptest.NewRecorder()
    handler := http.HandlerFunc(readyHandler)
    handler.ServeHTTP(rr, req)
    
    if status := rr.Code; status != http.StatusOK {
        t.Errorf("handler returned wrong status code: got %v want %v",
            status, http.StatusOK)
    }
}
```

## 探针工作流程

理解探针的工作流程有助于更好地配置和使用探针:

### Pod启动阶段

1. Pod被创建并调度到节点
2. kubelet开始拉取镜像并启动容器
3. 如果配置了启动探针,kubelet等待initialDelaySeconds后开始执行启动探针
4. 启动探针成功之前,存活探针和就绪探针被禁用
5. 启动探针成功后,存活探针和就绪探针开始工作
6. 就绪探针成功后,Pod开始接收流量

### Pod运行阶段

1. kubelet定期执行存活探针和就绪探针
2. 如果存活探针失败达到failureThreshold次,容器被重启
3. 如果就绪探针失败,Pod的IP从Service的端点列表中移除,停止接收新流量
4. 就绪探针恢复成功后,Pod重新加入Service的端点列表

### 探针状态转换图

```
启动探针: [未开始] -> [执行中] -> [成功] -> [不再执行]
                              \-> [失败] -> [容器重启]

存活探针: [禁用(启动探针未成功)] -> [执行中] -> [成功] -> [继续执行]
                                              \-> [失败计数++] -> [达到阈值则重启]

就绪探针: [禁用(启动探针未成功)] -> [执行中] -> [成功(加入端点)] -> [继续执行]
                                              \-> [失败(移除端点)] -> [继续执行]
```

## 常见问题和解决方案

### 问题1: 容器频繁重启

**症状**: 容器不断被重启,查看事件显示Liveness probe failed

**可能原因**:
- 存活探针配置过于严格
- 应用启动时间长,但initialDelaySeconds设置过短
- 应用在高负载时无法及时响应探针
- 探针检查了外部依赖,外部依赖不稳定

**解决方案**:
1. 检查应用日志,确定应用是否真的不健康
2. 增加initialDelaySeconds或使用启动探针
3. 增加timeoutSeconds和failureThreshold
4. 存活探针不要检查外部依赖,只检查应用本身
5. 优化应用性能,确保能快速响应探针

示例:

```yaml
# 优化前
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 10
  timeoutSeconds: 1
  failureThreshold: 1

# 优化后
startupProbe:
  httpGet:
    path: /healthz
    port: 8080
  periodSeconds: 10
  failureThreshold: 30  # 给应用300秒启动时间

livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3
```

### 问题2: Pod一直处于NotReady状态

**症状**: Pod运行正常但一直不接收流量,状态显示0/1 Ready

**可能原因**:
- 就绪探针配置错误
- 应用确实未就绪(如依赖服务不可用)
- 就绪探针端点返回错误的状态码
- initialDelaySeconds设置过长

**解决方案**:
1. 检查就绪探针的配置是否正确
2. 手动访问就绪探针端点,查看返回结果
3. 查看应用日志,确定应用是否真的未就绪
4. 检查应用依赖的服务是否可用
5. 调整就绪探针的检查逻辑

```go
// 添加详细日志帮助排查
func (hc *HealthChecker) ReadinessHandler(w http.ResponseWriter, r *http.Request) {
    checks := []struct {
        name  string
        check func() bool
    }{
        {"database", hc.checkDB},
        {"cache", hc.checkCache},
    }
    
    allReady := true
    for _, c := range checks {
        if !c.check() {
            log.Printf("Readiness check failed: %s", c.name)
            allReady = false
        }
    }
    
    if allReady {
        w.WriteHeader(http.StatusOK)
    } else {
        w.WriteHeader(http.StatusServiceUnavailable)
    }
}
```

### 问题3: 探针导致应用性能下降

**症状**: 应用响应变慢,CPU使用率升高,与探针检查频率相关

**可能原因**:
- 探针检查频率过高(periodSeconds过小)
- 探针端点执行耗时操作
- 大量Pod同时进行探针检查
- 探针检查会触发资源密集型操作

**解决方案**:
1. 增加periodSeconds,降低检查频率
2. 优化健康检查端点,使其更轻量级
3. 使用缓存减少对外部依赖的检查
4. 避免在健康检查中执行复杂逻辑

```go
// 优化健康检查,使用缓存
type OptimizedHealthChecker struct {
    dbCheckCache struct {
        sync.RWMutex
        result    bool
        timestamp time.Time
    }
    cacheTTL time.Duration
}

func (hc *OptimizedHealthChecker) checkDatabaseCached() bool {
    // 读取缓存
    hc.dbCheckCache.RLock()
    if time.Since(hc.dbCheckCache.timestamp) < hc.cacheTTL {
        result := hc.dbCheckCache.result
        hc.dbCheckCache.RUnlock()
        return result
    }
    hc.dbCheckCache.RUnlock()
    
    // 更新缓存
    hc.dbCheckCache.Lock()
    defer hc.dbCheckCache.Unlock()
    
    // 双重检查
    if time.Since(hc.dbCheckCache.timestamp) < hc.cacheTTL {
        return hc.dbCheckCache.result
    }
    
    result := hc.actualDatabaseCheck()
    hc.dbCheckCache.result = result
    hc.dbCheckCache.timestamp = time.Now()
    return result
}
```

### 问题4: 滚动更新时出现服务中断

**症状**: 在滚动更新过程中,部分请求失败或超时

**可能原因**:
- 新Pod还未就绪就开始接收流量
- 旧Pod被终止时还在处理请求
- 就绪探针配置不合理
- 没有正确配置terminationGracePeriodSeconds

**解决方案**:
1. 确保就绪探针正确配置
2. 配置合理的minReadySeconds
3. 实现优雅关闭逻辑
4. 配置preStop hook

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  minReadySeconds: 10  # 确保Pod稳定后才标记为可用
  template:
    spec:
      containers:
      - name: app
        image: myapp:latest
        lifecycle:
          preStop:
            exec:
              command:
              - sh
              - -c
              - sleep 15  # 给负载均衡器时间移除端点
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          successThreshold: 1
        terminationGracePeriodSeconds: 30
```

### 问题5: 探针检查外部依赖导致级联故障

**症状**: 当外部服务(如数据库)出现问题时,所有Pod都被标记为不健康或被重启

**可能原因**:
- 存活探针检查了外部依赖
- 外部依赖暂时不可用
- 探针配置没有区分临时故障和永久故障

**解决方案**:
1. 存活探针只检查应用本身,不检查外部依赖
2. 就绪探针可以检查外部依赖
3. 实现重试和断路器机制
4. 区分关键依赖和非关键依赖

```go
// 区分关键依赖和非关键依赖
type DependencyChecker struct {
    db    *sql.DB
    cache *redis.Client
}

// 存活探针:只检查应用本身
func (dc *DependencyChecker) LivenessHandler(w http.ResponseWriter, r *http.Request) {
    // 简单的内存检查或心跳检查
    w.WriteHeader(http.StatusOK)
}

// 就绪探针:检查关键依赖
func (dc *DependencyChecker) ReadinessHandler(w http.ResponseWriter, r *http.Request) {
    // 只检查关键依赖(数据库),缓存是非关键依赖
    if !dc.checkDatabaseWithTimeout(2 * time.Second) {
        w.WriteHeader(http.StatusServiceUnavailable)
        return
    }
    
    w.WriteHeader(http.StatusOK)
}

func (dc *DependencyChecker) checkDatabaseWithTimeout(timeout time.Duration) bool {
    ctx, cancel := context.WithTimeout(context.Background(), timeout)
    defer cancel()
    
    return dc.db.PingContext(ctx) == nil
}
```

## 与其他Kubernetes特性的集成

### 与HPA(Horizontal Pod Autoscaler)的配合

HPA根据资源使用率或自定义指标自动扩缩容,探针确保只有健康的Pod才会被计入:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  template:
    spec:
      containers:
      - name: app
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
```

### 与PodDisruptionBudget的配合

PodDisruptionBudget确保在自愿中断期间保持最小可用Pod数量,配合就绪探针使用:

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: myapp-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: myapp
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
        terminationGracePeriodSeconds: 60
```

### 与Service的配合

Service通过就绪探针来决定哪些Pod应该接收流量:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  selector:
    app: myapp
  ports:
  - port: 80
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
```

## 监控和调试探针

### 查看探针状态

使用kubectl查看Pod的探针状态:

```bash
# 查看Pod详细信息,包括探针配置和状态
kubectl describe pod <pod-name>

# 查看Pod事件,包括探针失败事件
kubectl get events --field-selector involvedObject.name=<pod-name>

# 查看Pod的就绪状态
kubectl get pods -o wide
```

### 使用kubectl调试

```bash
# 端口转发到Pod,手动测试健康检查端点
kubectl port-forward pod/<pod-name> 8080:8080

# 在另一个终端测试
curl http://localhost:8080/healthz
curl http://localhost:8080/ready

# 查看Pod日志
kubectl logs <pod-name>

# 进入Pod容器执行命令
kubectl exec -it <pod-name> -- /bin/sh
```

### 使用Prometheus监控探针

在应用中暴露探针相关的指标:

```go
package main

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
    "github.com/prometheus/client_golang/prometheus/promhttp"
    "net/http"
    "time"
)

var (
    livenessCheckDuration = promauto.NewHistogram(prometheus.HistogramOpts{
        Name: "liveness_check_duration_seconds",
        Help: "Duration of liveness check",
    })
    
    readinessCheckDuration = promauto.NewHistogram(prometheus.HistogramOpts{
        Name: "readiness_check_duration_seconds",
        Help: "Duration of readiness check",
    })
    
    probeFailures = promauto.NewCounterVec(prometheus.CounterOpts{
        Name: "probe_failures_total",
        Help: "Total number of probe failures",
    }, []string{"probe_type"})
)

func instrumentedHealthHandler(handler func(http.ResponseWriter, *http.Request), probeType string, histogram prometheus.Histogram) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()
        
        // 使用自定义ResponseWriter捕获状态码
        rw := &responseWriter{ResponseWriter: w, statusCode: http.StatusOK}
        handler(rw, r)
        
        duration := time.Since(start).Seconds()
        histogram.Observe(duration)
        
        if rw.statusCode >= 400 {
            probeFailures.WithLabelValues(probeType).Inc()
        }
    }
}

type responseWriter struct {
    http.ResponseWriter
    statusCode int
}

func (rw *responseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}

func main() {
    http.Handle("/metrics", promhttp.Handler())
    http.HandleFunc("/healthz", instrumentedHealthHandler(healthzHandler, "liveness", livenessCheckDuration))
    http.HandleFunc("/ready", instrumentedHealthHandler(readyHandler, "readiness", readinessCheckDuration))
    http.ListenAndServe(":8080", nil)
}

func healthzHandler(w http.ResponseWriter, r *http.Request) {
    w.WriteHeader(http.StatusOK)
}

func readyHandler(w http.ResponseWriter, r *http.Request) {
    w.WriteHeader(http.StatusOK)
}
```

## 总结

Kubernetes的探针机制是实现应用高可用性的重要工具。通过合理配置和使用三种探针(启动探针、存活探针、就绪探针),可以让Kubernetes更智能地管理应用的生命周期,自动处理故障,确保服务的稳定性。

关键要点:
- 理解三种探针的不同用途和适用场景
- 根据应用特性选择合适的探针类型和检查方式
- 合理配置探针参数,避免误杀和漏检
- 区分关键依赖和非关键依赖
- 实现轻量级的健康检查端点
- 配合优雅关闭实现零宕机部署
- 监控探针状态,及时发现和解决问题

正确使用探针机制,可以显著提高应用的可靠性和用户体验,是生产环境中不可或缺的配置。

---

## 常见问题FAQ

### Q1: 存活探针和就绪探针有什么区别?何时使用?

**区别:**

存活探针(Liveness Probe)用于检测容器是否还在运行,如果失败会导致容器重启。主要用于检测应用是否陷入死锁、死循环或其他不可恢复的状态。

就绪探针(Readiness Probe)用于检测容器是否准备好接收流量,如果失败只会将Pod从Service的端点列表中移除,不会重启容器。主要用于处理临时性的不可用状态。

**使用建议:**

- 存活探针应该简单快速,只检查应用本身是否存活,不要检查外部依赖
- 就绪探针可以检查外部依赖(如数据库、缓存),确保应用能正常提供服务
- 不要让两个探针使用相同的检查逻辑
- 如果应用启动慢,优先使用启动探针而不是增加存活探针的initialDelaySeconds

### Q2: 为什么我的Pod一直被重启?如何排查和解决?

**常见原因:**

1. 存活探针配置过于严格,failureThreshold设置为1或timeoutSeconds过短
2. 应用启动时间长,但没有配置足够的initialDelaySeconds或启动探针
3. 应用在高负载时响应变慢,无法及时响应探针
4. 探针检查了不稳定的外部依赖
5. 健康检查端点本身有bug或性能问题

**排查步骤:**

```bash
# 1. 查看Pod事件,确认重启原因
kubectl describe pod <pod-name>

# 2. 查看Pod日志,了解应用状态
kubectl logs <pod-name>
kubectl logs <pod-name> --previous  # 查看上一个容器的日志

# 3. 手动测试健康检查端点
kubectl port-forward pod/<pod-name> 8080:8080
curl -v http://localhost:8080/healthz

# 4. 查看资源使用情况
kubectl top pod <pod-name>
```

**解决方案:**

```yaml
# 1. 使用启动探针处理慢启动
startupProbe:
  httpGet:
    path: /healthz
    port: 8080
  failureThreshold: 30
  periodSeconds: 10

# 2. 调整存活探针参数
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  timeoutSeconds: 5        # 增加超时时间
  periodSeconds: 10        # 降低检查频率
  failureThreshold: 3      # 允许失败3次

# 3. 简化存活探针,不检查外部依赖
livenessProbe:
  httpGet:
    path: /ping  # 简单的ping端点
    port: 8080
```

### Q3: 应用启动很慢(超过1分钟),应该如何配置探针?

对于启动缓慢的应用,正确的做法是使用启动探针,而不是简单地增加存活探针的initialDelaySeconds:

```yaml
# 推荐配置
startupProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 0
  periodSeconds: 10
  failureThreshold: 60  # 最多等待600秒(10分钟)
  timeoutSeconds: 3

livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3
```

**优点:**
- 启动阶段有足够时间(最多10分钟)
- 启动成功后,存活探针能快速检测问题(最多30秒)
- 就绪探针确保应用完全准备好才接收流量

**在应用代码中的实现:**

```go
type SlowStartApp struct {
    started atomic.Bool
    ready   atomic.Bool
}

func (app *SlowStartApp) Initialize() {
    log.Println("Starting slow initialization...")
    
    // 模拟慢启动过程
    time.Sleep(90 * time.Second)
    app.started.Store(true)
    log.Println("Initialization complete")
    
    // 额外的就绪准备
    time.Sleep(10 * time.Second)
    app.ready.Store(true)
    log.Println("Ready to serve traffic")
}

func (app *SlowStartApp) HealthzHandler(w http.ResponseWriter, r *http.Request) {
    if app.started.Load() {
        w.WriteHeader(http.StatusOK)
        w.Write([]byte("Started"))
    } else {
        w.WriteHeader(http.StatusServiceUnavailable)
        w.Write([]byte("Starting..."))
    }
}

func (app *SlowStartApp) ReadyHandler(w http.ResponseWriter, r *http.Request) {
    if app.ready.Load() {
        w.WriteHeader(http.StatusOK)
    } else {
        w.WriteHeader(http.StatusServiceUnavailable)
    }
}
```

### Q4: 健康检查端点应该检查哪些内容?是否应该检查数据库等外部依赖?

这取决于使用哪种探针:

**存活探针 - 不应该检查外部依赖:**

```go
// 存活探针:简单快速,只检查应用本身
func LivenessHandler(w http.ResponseWriter, r *http.Request) {
    // 方案1: 简单的ping
    w.WriteHeader(http.StatusOK)
    w.Write([]byte("OK"))
    
    // 方案2: 检查关键内部状态
    if appIsDeadlocked() {
        w.WriteHeader(http.StatusServiceUnavailable)
        return
    }
    w.WriteHeader(http.StatusOK)
}
```

**原因:** 如果数据库暂时不可用,不应该重启应用容器,而应该等待数据库恢复。

**就绪探针 - 可以检查关键外部依赖:**

```go
// 就绪探针:检查应用是否真正能提供服务
func ReadinessHandler(w http.ResponseWriter, r *http.Request) {
    checks := []struct {
        name     string
        check    func() bool
        critical bool  // 是否关键依赖
    }{
        {"database", checkDatabase, true},
        {"cache", checkCache, false},  // 缓存不是关键依赖
        {"message_queue", checkMQ, true},
    }
    
    for _, c := range checks {
        if c.critical && !c.check() {
            log.Printf("Readiness failed: %s unavailable", c.name)
            w.WriteHeader(http.StatusServiceUnavailable)
            return
        }
    }
    
    w.WriteHeader(http.StatusOK)
}

func checkDatabase() bool {
    ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
    defer cancel()
    return db.PingContext(ctx) == nil
}
```

**最佳实践:**
- 区分关键依赖和非关键依赖
- 使用超时避免探针阻塞
- 使用缓存减少对外部系统的压力
- 记录详细日志帮助排查问题

### Q5: 在滚动更新时如何实现零宕机部署?

零宕机部署需要正确配置多个参数并实现优雅关闭:

**1. Deployment配置:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1      # 最多1个Pod不可用
      maxSurge: 1            # 最多额外1个Pod
  minReadySeconds: 10        # Pod稳定10秒后才视为可用
  template:
    spec:
      containers:
      - name: app
        lifecycle:
          preStop:
            exec:
              command:
              - sh
              - -c
              - sleep 15   # 等待负载均衡器更新
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          successThreshold: 1
          failureThreshold: 1
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
        terminationGracePeriodSeconds: 30
```

**2. 应用实现优雅关闭:**

```go
package main

import (
    "context"
    "log"
    "net/http"
    "os"
    "os/signal"
    "sync/atomic"
    "syscall"
    "time"
)

type GracefulApp struct {
    server *http.Server
    ready  atomic.Bool
}

func (app *GracefulApp) ReadyHandler(w http.ResponseWriter, r *http.Request) {
    if app.ready.Load() {
        w.WriteHeader(http.StatusOK)
    } else {
        w.WriteHeader(http.StatusServiceUnavailable)
    }
}

func (app *GracefulApp) Shutdown() {
    log.Println("Received shutdown signal")
    
    // 步骤1: 标记为未就绪,停止接收新请求
    app.ready.Store(false)
    log.Println("Marked as not ready")
    
    // 步骤2: 等待负载均衡器更新(大于就绪探针间隔)
    time.Sleep(15 * time.Second)
    log.Println("Waited for load balancer to update")
    
    // 步骤3: 优雅关闭服务器,等待现有请求完成
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()
    
    if err := app.server.Shutdown(ctx); err != nil {
        log.Printf("Server shutdown error: %v", err)
    }
    
    log.Println("Server gracefully stopped")
}

func (app *GracefulApp) Start() {
    mux := http.NewServeMux()
    mux.HandleFunc("/ready", app.ReadyHandler)
    mux.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
        // 模拟慢请求
        time.Sleep(2 * time.Second)
        w.Write([]byte("OK"))
    })
    
    app.server = &http.Server{
        Addr:    ":8080",
        Handler: mux,
    }
    
    // 应用启动后标记为就绪
    app.ready.Store(true)
    
    go func() {
        log.Println("Server starting on :8080")
        if err := app.server.ListenAndServe(); err != http.ErrServerClosed {
            log.Fatalf("Server error: %v", err)
        }
    }()
    
    // 等待终止信号
    quit := make(chan os.Signal, 1)
    signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
    <-quit
    
    app.Shutdown()
}

func main() {
    app := &GracefulApp{}
    app.Start()
}
```

**关键点:**
- preStop hook给负载均衡器时间更新端点
- 优雅关闭等待现有请求完成
- terminationGracePeriodSeconds足够长
- minReadySeconds确保新Pod稳定后才接收流量
- maxUnavailable和maxSurge控制更新速度