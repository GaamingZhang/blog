# DevOps流水线中执行器的调度

## 概述

在DevOps流水线中,执行器(Executor/Agent/Runner)是实际运行构建、测试和部署任务的计算节点。执行器调度是CI/CD系统的核心功能之一,负责将待执行的任务分配给合适的执行器,确保资源的高效利用和任务的及时完成。

本文将深入探讨执行器调度的原理、策略、实现和最佳实践,帮助您构建高效稳定的DevOps流水线。

## 执行器基础

### 执行器类型

**1. 静态执行器(Static Executor)**

静态执行器是预先配置好的固定节点,始终处于运行状态。

**特点:**
- 启动快速,立即可用
- 资源始终占用
- 配置固定,环境稳定
- 适合高频任务

**使用场景:**
- 持续集成的主要构建任务
- 需要快速响应的场景
- 特殊硬件或软件环境

**配置示例(Jenkins):**
```groovy
// Jenkins静态节点配置
node('linux-builder') {
    stage('Build') {
        sh 'make build'
    }
}
```

**2. 动态执行器(Dynamic Executor)**

动态执行器按需创建,任务完成后销毁。

**特点:**
- 资源利用率高
- 启动时间较长
- 环境隔离性好
- 成本优化

**使用场景:**
- 资源密集型任务
- 需要特定环境的临时任务
- 峰值负载处理

**配置示例(GitLab Runner):**
```yaml
# .gitlab-ci.yml
build:
  tags:
    - docker
  image: node:18
  script:
    - npm install
    - npm run build
```

**3. 容器化执行器(Container-based Executor)**

使用容器技术(Docker、Kubernetes)提供执行环境。

**特点:**
- 环境一致性强
- 快速启动和销毁
- 资源隔离
- 可移植性高

**Kubernetes执行器示例:**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: build-executor
spec:
  containers:
  - name: builder
    image: gradle:7-jdk11
    command: ['sleep', '3600']
    resources:
      requests:
        memory: "2Gi"
        cpu: "1"
      limits:
        memory: "4Gi"
        cpu: "2"
```

**4. 云端执行器(Cloud-based Executor)**

利用云服务提供商的计算资源。

**优势:**
- 弹性伸缩能力
- 按使用付费
- 无需维护基础设施
- 全球分布

**支持的平台:**
- AWS CodeBuild
- Azure Pipelines
- Google Cloud Build
- GitHub Actions (托管runner)

### 执行器架构

典型的执行器架构包含以下组件:

```
┌─────────────────────────────────────────────┐
│            CI/CD Master/Server              │
│  ┌──────────────────────────────────────┐  │
│  │      Job Queue                       │  │
│  │  ┌────┐ ┌────┐ ┌────┐ ┌────┐       │  │
│  │  │Job1│ │Job2│ │Job3│ │Job4│       │  │
│  │  └────┘ └────┘ └────┘ └────┘       │  │
│  └──────────────────────────────────────┘  │
│  ┌──────────────────────────────────────┐  │
│  │      Scheduler                       │  │
│  │  - 任务分配                          │  │
│  │  - 负载均衡                          │  │
│  │  - 资源匹配                          │  │
│  └──────────────────────────────────────┘  │
└─────────────────────────────────────────────┘
                    │
        ┌───────────┼───────────┐
        ↓           ↓           ↓
┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│  Executor 1  │ │  Executor 2  │ │  Executor 3  │
│  Label: linux│ │ Label: docker│ │ Label: macos │
│  Slots: 2    │ │ Slots: 4     │ │ Slots: 1     │
│  Load: 50%   │ │ Load: 75%    │ │ Load: 100%   │
└──────────────┘ └──────────────┘ └──────────────┘
```

## 调度策略

### 1. 标签路由(Label-based Routing)

通过标签(Label/Tag)将任务路由到特定的执行器。

**实现原理:**
- 执行器注册时声明自己的标签
- 任务定义所需的标签
- 调度器匹配标签进行分配

**GitLab CI示例:**
```yaml
# 注册Runner时设置标签
# gitlab-runner register --tag-list "docker,linux,x64"

build-linux:
  tags:
    - docker
    - linux
  script:
    - make build

build-macos:
  tags:
    - macos
    - xcode
  script:
    - xcodebuild
```

**Jenkins标签配置:**
```groovy
pipeline {
    agent {
        label 'linux && docker && high-memory'
    }
    stages {
        stage('Build') {
            steps {
                sh 'docker build -t myapp .'
            }
        }
    }
}
```

**标签设计最佳实践:**
- 操作系统: `linux`, `windows`, `macos`
- 架构: `x64`, `arm64`
- 工具: `docker`, `kubernetes`, `maven`
- 资源: `high-cpu`, `high-memory`, `gpu`
- 环境: `dev`, `staging`, `production`

### 2. 负载均衡(Load Balancing)

在多个可用执行器之间分配任务,避免单点过载。

**常见算法:**
- **轮询(Round Robin)**: 依次分配给每个执行器
- **最少连接(Least Connections)**: 选择当前任务数最少的执行器
- **加权轮询(Weighted Round Robin)**: 根据执行器容量分配权重

**实现示例:**
```python
class LoadBalancer:
    def schedule(self, job, executors):
        # 选择当前任务数最少的执行器
        return min(executors, key=lambda e: e.active_jobs)
```

### 3. 资源感知调度(Resource-aware Scheduling)

根据任务的资源需求和执行器的资源可用性进行调度。

**资源请求声明:**
```yaml
# GitLab CI
build-heavy:
  tags:
    - kubernetes
  variables:
    KUBERNETES_CPU_REQUEST: "2"
    KUBERNETES_CPU_LIMIT: "4"
    KUBERNETES_MEMORY_REQUEST: "4Gi"
    KUBERNETES_MEMORY_LIMIT: "8Gi"
  script:
    - npm run build
```

**Kubernetes资源调度:**
```yaml
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: build
    resources:
      requests:
        memory: "2Gi"
        cpu: "1"
      limits:
        memory: "4Gi"
        cpu: "2"
  # Kubernetes调度器会根据节点资源选择合适的节点
```

**资源调度算法:**
```python
def resource_aware_schedule(job, executors):
    """
    根据资源需求选择执行器
    """
    required_cpu = job.cpu_request
    required_memory = job.memory_request
    
    # 筛选满足资源要求的执行器
    suitable_executors = [
        e for e in executors
        if e.available_cpu >= required_cpu
        and e.available_memory >= required_memory
    ]
    
    if not suitable_executors:
        return None  # 没有可用执行器,任务排队
    
    # 选择资源最充足的执行器
    return max(suitable_executors, 
               key=lambda e: e.available_cpu + e.available_memory)
```

### 4. 优先级调度(Priority-based Scheduling)

根据任务优先级决定执行顺序。

**优先级定义:**
```yaml
# Jenkins
pipeline {
    options {
        // 设置构建优先级
        buildPriority(100)  // 0-100,数值越大优先级越高
    }
}
```

**优先级队列实现:**
```python
import heapq
from dataclasses import dataclass, field
from typing import Any

@dataclass(order=True)
class PrioritizedJob:
    priority: int
    job: Any = field(compare=False)

class PriorityScheduler:
    def __init__(self):
        self.queue = []
    
    def add_job(self, job, priority):
        # 使用负优先级,使高优先级任务先出队
        heapq.heappush(self.queue, PrioritizedJob(-priority, job))
    
    def get_next_job(self):
        if self.queue:
            return heapq.heappop(self.queue).job
        return None
```

**优先级策略:**
- **Critical (100)**: 生产环境热修复
- **High (80)**: 主分支构建
- **Normal (50)**: 功能分支构建
- **Low (20)**: 定时任务、清理任务

### 5. 公平调度(Fair Scheduling)

确保不同用户或项目获得公平的资源分配。

**核心思想:**
- 记录每个项目的资源使用情况
- 优先调度资源使用率低于公平份额的项目
- 使用配额限制单个项目的资源占用

**Kubernetes配额管理:**
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: project-a-quota
spec:
  hard:
    requests.cpu: "10"
    requests.memory: "20Gi"
    pods: "20"
```

### 6. 亲和性与反亲和性调度

控制任务在执行器上的分布。

**节点亲和性(Node Affinity):**
```yaml
# Kubernetes
apiVersion: v1
kind: Pod
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disk-type
            operator: In
            values:
            - ssd
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: zone
            operator: In
            values:
            - us-west-1a
```

**Pod反亲和性(Anti-affinity):**
```yaml
# 避免同一应用的多个实例调度到同一节点
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - build-executor
        topologyKey: kubernetes.io/hostname
```

## 执行器管理

### 执行器注册与发现

**静态注册:**
```bash
# GitLab Runner手动注册
gitlab-runner register \
  --url https://gitlab.com/ \
  --registration-token $TOKEN \
  --executor docker \
  --tag-list "docker,linux"
```

**动态注册(自动发现):**
执行器启动时自动向CI服务器注册,提供主机名、IP、标签、容量等信息。服务器验证后将其加入可用执行器池。

### 健康检查

**心跳机制:**
执行器定期(如每30秒)向服务器发送心跳信息,包含状态、资源使用情况等。服务器检测超时未响应的执行器并标记为不可用。

**Kubernetes健康探针:**
```yaml
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: executor
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
```

### 执行器生命周期管理

**自动扩缩容(Autoscaling):**

```yaml
# Kubernetes HPA for Jenkins agents
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: jenkins-agent-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: jenkins-agent
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Pods
    pods:
      metric:
        name: jobs_queued
      target:
        type: AverageValue
        averageValue: "2"
```

**按需创建和销毁:**
```python
class ExecutorPool:
    def __init__(self, min_executors=2, max_executors=10):
        self.min_executors = min_executors
        self.max_executors = max_executors
        self.executors = []
    
    def scale_up(self, count=1):
        """增加执行器"""
        if len(self.executors) >= self.max_executors:
            return False
        
        for _ in range(count):
            executor = self._create_executor()
            self.executors.append(executor)
        
        return True
    
    def scale_down(self, count=1):
        """减少执行器"""
        if len(self.executors) <= self.min_executors:
            return False
        
        # 选择空闲的执行器删除
        idle_executors = [e for e in self.executors if e.is_idle()]
        
        for executor in idle_executors[:count]:
            self._destroy_executor(executor)
            self.executors.remove(executor)
        
        return True
    
    def auto_scale(self):
        """自动扩缩容"""
        queue_length = self._get_queue_length()
        active_executors = len([e for e in self.executors if not e.is_idle()])
        
        # 扩容条件: 队列长度 > 活跃执行器数 * 2
        if queue_length > active_executors * 2:
            scale_count = min(
                queue_length // 2,
                self.max_executors - len(self.executors)
            )
            self.scale_up(scale_count)
        
        # 缩容条件: 空闲执行器 > 最小数量
        elif len([e for e in self.executors if e.is_idle()]) > self.min_executors:
            self.scale_down(1)
```

## 并发控制

### 全局并发限制

**限制总并发数:**
```groovy
// Jenkins Pipeline
options {
    // 限制整个系统同时运行的构建数
    throttle(['global_limit'])
}
```

**Kubernetes资源配额:**
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: ci-quota
spec:
  hard:
    pods: "50"
    requests.cpu: "100"
    requests.memory: "200Gi"
    persistentvolumeclaims: "20"
```

### 项目级并发限制

**Jenkins配置:**
```groovy
// Jenkinsfile
options {
    // 禁止同一项目并发构建
    disableConcurrentBuilds()
    
    // 或使用throttle限制并发数
    throttle(['project-a', 'max-per-project': 3])
}
```

**GitLab CI配置:**
```yaml
# .gitlab-ci.yml
workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      variables:
        # 限制MR流水线并发
        CI_CONCURRENT_PROJECT_ID: "3"
```

### 执行器级并发限制

**执行器并发槽位:**
```python
class Executor:
    def __init__(self, max_concurrent_jobs=4):
        self.max_concurrent_jobs = max_concurrent_jobs
        self.active_jobs = []
    
    def can_accept_job(self):
        return len(self.active_jobs) < self.max_concurrent_jobs
    
    def accept_job(self, job):
        if not self.can_accept_job():
            return False
        
        self.active_jobs.append(job)
        return True
    
    def release_job(self, job):
        if job in self.active_jobs:
            self.active_jobs.remove(job)
```

**配置示例:**
```yaml
# GitLab Runner config.toml
[[runners]]
  name = "docker-runner"
  limit = 4  # 最多同时运行4个任务
  
  [runners.docker]
    image = "ruby:2.7"
```

### 资源锁(Resource Locking)

用于保护共享资源,防止并发访问冲突。

**Lockable Resources Plugin (Jenkins):**
```groovy
pipeline {
    agent any
    stages {
        stage('Deploy') {
            options {
                lock(resource: 'production-environment', skipIfLocked: false)
            }
            steps {
                sh 'deploy.sh production'
            }
        }
    }
}
```

**自定义资源锁实现:**
```python
import threading
from contextlib import contextmanager

class ResourceLock:
    def __init__(self):
        self.locks = {}
        self.lock_manager = threading.Lock()
    
    @contextmanager
    def acquire(self, resource_name, timeout=300):
        """获取资源锁"""
        with self.lock_manager:
            if resource_name not in self.locks:
                self.locks[resource_name] = threading.Lock()
        
        lock = self.locks[resource_name]
        acquired = lock.acquire(timeout=timeout)
        
        if not acquired:
            raise TimeoutError(f"Failed to acquire lock for {resource_name}")
        
        try:
            yield
        finally:
            lock.release()

# 使用示例
resource_lock = ResourceLock()

def deploy_job():
    with resource_lock.acquire('production-db'):
        # 执行部署操作
        migrate_database()
```

## 调度优化

### 任务预测与预加载

基于历史数据预测任务的资源需求和执行时间,提前分配合适的执行器。

### 任务打包(Job Packing)

将多个小任务打包到同一执行器,提高资源利用率。使用首次适应算法(First Fit)或最佳适应算法(Best Fit)。

### 缓存和工作空间管理

**依赖缓存:**
```yaml
# GitLab CI
build:
  cache:
    key: ${CI_COMMIT_REF_SLUG}
    paths:
      - node_modules/
  script:
    - npm install
    - npm run build
```

**Docker层缓存:**
```yaml
build-docker:
  script:
    - docker pull $IMAGE:latest || true
    - docker build --cache-from $IMAGE:latest -t $IMAGE:$SHA .
```

## 监控与可观测性

### 关键指标

**执行器指标:**
- 执行器数量(活跃/空闲)
- 任务队列长度
- 资源利用率(CPU/内存)

**调度指标:**
- 调度延迟
- 队列等待时间
- 调度失败率

### 日志和追踪

使用结构化日志记录调度决策,包含事件类型、任务ID、执行器信息、时间戳等关键信息。

### 告警规则

**典型告警:**
- 执行器不足: 队列积压且无空闲执行器
- 执行器失联: 心跳超时
- 等待时间过长: P95等待时间>10分钟
- 资源利用率过高: CPU/内存>90%

**Prometheus告警示例:**
```yaml
- alert: ExecutorShortage
  expr: job_queue_length > 10 and executor_count{status="idle"} == 0
  for: 5m
  annotations:
    summary: "执行器资源不足"
```

## 故障处理

### 执行器故障检测

**常见故障类型:**
1. 网络断连
2. 资源耗尽
3. 软件崩溃
4. 硬件故障

**检测方法:**
- 心跳超时检测
- 资源使用率监控
- 主动健康探测

### 任务重试机制

**GitLab CI重试配置:**
```yaml
test:
  script:
    - npm test
  retry:
    max: 3
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
```

**指数退避策略:**
失败后等待时间呈指数增长(1s, 2s, 4s, 8s...),加随机抖动避免雷鸣群效应。

### 优雅降级

资源压力时的降级策略:
- 禁用低优先级任务
- 降低并发限制
- 启用更严格的资源配额
- 压力缓解后自动恢复

## 最佳实践

### 1. 执行器配置

**合理规划资源:**
- Small (2核4G): 快速构建、单元测试
- Medium (4核8G): 标准构建、集成测试
- Large (8核16G): 大型项目、性能测试

**标签规范化:**
建立清晰的标签层次,如OS(linux/windows)、架构(x64/arm64)、工具(docker/maven)、能力(gpu/high-memory)、环境(dev/prod)。

### 2. 调度优化

**避免资源碎片:**
使用Bin Packing算法,按资源需求降序排列任务,优先分配大任务。

**平衡优先级与公平性:**
综合考虑任务优先级和等待时间,避免低优先级任务饥饿。

### 3. 资源管理

**动态调整:**
根据队列长度和利用率自动扩缩容。

**资源预留:**
为关键任务预留专用资源。

### 4. 故障恢复

建立自动恢复机制:
- 执行器故障: 重启或替换
- 网络分区: 重连和状态同步
- 资源耗尽: 清理和释放

### 5. 性能优化

**缓存预热:**
执行器启动时预先拉取常用镜像和工具。

**任务合并:**
合并相关小任务减少调度开销。

## 安全考虑

### 执行器隔离

**容器隔离:**
- 禁用特权模式
- 限制容器capabilities
- 使用只读根文件系统
- 应用安全选项(no-new-privileges)

**网络隔离:**
使用Kubernetes NetworkPolicy限制执行器的网络访问,只允许与必要的服务通信。

### 访问控制

**执行器认证:**
使用JWT或其他token机制验证执行器身份,防止未授权的执行器接入。

**任务授权:**
检查执行器是否有权限执行特定任务,包括标签匹配、环境权限、项目权限等。

### 审计日志

记录所有调度决策和执行操作,包括时间戳、执行器ID、任务信息、用户等,用于审计和问题追踪。

## 总结

执行器调度是DevOps流水线的核心组件,直接影响到CI/CD系统的效率、可靠性和成本。

**关键要点:**
1. **选择合适的执行器类型**: 根据场景选择静态、动态或容器化执行器
2. **实施智能调度策略**: 结合标签路由、负载均衡、资源感知等策略
3. **合理控制并发**: 在全局、项目和执行器级别设置并发限制
4. **持续监控和优化**: 收集指标、分析瓶颈、不断改进
5. **保障安全性**: 实施隔离、访问控制和审计
6. **建立故障恢复机制**: 自动检测、重试和降级

通过合理的执行器调度设计,可以显著提升流水线的吞吐量,缩短任务等待时间,提高资源利用率,为团队提供高效稳定的CI/CD体验。

## 常见问题

### 1. 如何选择执行器的并发数(Concurrency)?

执行器并发数的选择需要综合考虑多个因素:

**计算公式:**
```
推荐并发数 = (CPU核心数 × CPU利用率目标) / 单任务平均CPU使用
```

**实际案例:**
假设一台8核16GB内存的机器:
- 如果运行CPU密集型任务(如编译),每个任务平均使用2核,设置并发数为3-4
- 如果运行IO密集型任务(如测试),每个任务平均使用0.5核,设置并发数为8-12

**配置示例:**
```yaml
# GitLab Runner - 根据资源设置并发
[[runners]]
  name = "docker-runner"
  limit = 4  # 最多同时4个任务
  
  [runners.docker]
    cpus = "2"      # 每个容器2核
    memory = "4g"   # 每个容器4GB
```

**动态调整策略:**
```python
def calculate_optimal_concurrency(executor):
    """动态计算最优并发数"""
    cpu_cores = executor.total_cpu
    memory_gb = executor.total_memory / 1024
    
    # 基于历史数据
    avg_cpu_per_job = executor.get_avg_cpu_usage()
    avg_memory_per_job = executor.get_avg_memory_usage()
    
    # 计算CPU和内存能支持的并发数
    cpu_based = int(cpu_cores * 0.8 / avg_cpu_per_job)
    memory_based = int(memory_gb * 0.8 / avg_memory_per_job)
    
    # 取较小值,留20%缓冲
    return min(cpu_based, memory_based)
```

**监控和调优:**
```bash
# 监控执行器资源使用
watch -n 5 'echo "=== CPU ===" && top -bn1 | head -5 && \
            echo "=== Memory ===" && free -h && \
            echo "=== Running Jobs ===" && docker ps | wc -l'
```

**建议:**
- 从保守值开始(如CPU核心数的50%)
- 监控资源使用率1-2周
- 逐步调整,每次增加1-2个并发
- 目标: CPU 60-80%, 内存 70-85%
- 避免过度订阅导致OOM或任务超时

### 2. 执行器标签(Label/Tag)应该如何设计?

良好的标签设计是高效调度的基础。

**标签层次结构:**
```yaml
# 推荐的标签分类
infrastructure:
  - physical    # 物理机
  - vm          # 虚拟机
  - container   # 容器
  - cloud       # 云端

os:
  - linux
  - windows
  - macos

architecture:
  - x64
  - arm64
  - arm

runtime:
  - docker
  - kubernetes
  - podman

tools:
  - maven
  - gradle
  - npm
  - python
  - go

capabilities:
  - gpu
  - high-cpu      # >8核
  - high-memory   # >16GB
  - ssd
  - network-fast  # 高带宽

environment:
  - dev
  - staging
  - production

region:
  - us-east
  - eu-west
  - asia-pacific
```

**实际配置示例:**
```bash
# GitLab Runner注册
gitlab-runner register \
  --tag-list "docker,linux,x64,high-cpu,ssd,dev,us-east"
```

**任务使用标签:**
```yaml
# .gitlab-ci.yml
build-backend:
  tags:
    - docker      # 需要Docker
    - linux       # Linux系统
    - high-cpu    # 高CPU配置
  script:
    - ./gradlew build

build-ios:
  tags:
    - macos       # macOS系统
    - xcode       # Xcode工具
  script:
    - xcodebuild

deploy-production:
  tags:
    - kubernetes  # K8s环境
    - production  # 生产权限
  script:
    - kubectl apply -f k8s/
```

**标签组合策略:**
```python
class LabelMatcher:
    def match(self, job_labels, executor_labels):
        """
        标签匹配规则:
        1. 必须标签(required): 所有必须标签都要匹配
        2. 可选标签(optional): 至少匹配一个
        3. 排除标签(exclude): 不能包含排除标签
        """
        required = set(job_labels.get('required', []))
        optional = set(job_labels.get('optional', []))
        exclude = set(job_labels.get('exclude', []))
        
        executor_set = set(executor_labels)
        
        # 检查必须标签
        if not required.issubset(executor_set):
            return False
        
        # 检查排除标签
        if exclude.intersection(executor_set):
            return False
        
        # 检查可选标签
        if optional and not optional.intersection(executor_set):
            return False
        
        return True
```

**最佳实践:**
1. **保持简洁**: 每个执行器5-10个标签
2. **语义明确**: 使用清晰的命名
3. **避免冗余**: 不要重复表达相同信息
4. **版本管理**: 工具标签包含版本(如`node-18`)
5. **文档化**: 维护标签清单和说明文档

### 3. 如何处理执行器资源不足导致的任务排队?

任务排队是常见问题,需要多方面应对。

**短期解决方案:**

**1. 手动扩容**
```bash
# 快速添加执行器
for i in {1..3}; do
  docker run -d \
    --name gitlab-runner-$i \
    -v /var/run/docker.sock:/var/run/docker.sock \
    gitlab/gitlab-runner:latest
    
  docker exec gitlab-runner-$i \
    gitlab-runner register \
    --non-interactive \
    --url $GITLAB_URL \
    --registration-token $TOKEN \
    --executor docker
done
```

**2. 优先级调整**
```yaml
# 提升关键任务优先级
hotfix-deploy:
  priority: 100  # 最高优先级
  tags:
    - production
  script:
    - deploy.sh
```

**中期解决方案:**

**1. 自动扩缩容**
```python
class AutoScaler:
    def __init__(self, min_executors=2, max_executors=10):
        self.min = min_executors
        self.max = max_executors
    
    def evaluate(self, metrics):
        """评估是否需要扩缩容"""
        queue_length = metrics['queue_length']
        avg_wait_time = metrics['avg_wait_time']
        active_executors = metrics['active_executors']
        
        # 扩容条件
        if queue_length > 10 or avg_wait_time > 300:
            if active_executors < self.max:
                scale_count = min(
                    queue_length // 3,  # 每3个任务添加1个执行器
                    self.max - active_executors
                )
                self.scale_up(scale_count)
        
        # 缩容条件
        elif queue_length == 0 and avg_wait_time < 60:
            idle_time = metrics['executor_idle_time']
            if idle_time > 600 and active_executors > self.min:
                self.scale_down(1)
```

**2. 云端突发容量**
```yaml
# 配置云端执行器作为突发容量
[[runners]]
  name = "cloud-burst-runner"
  
  # 只在队列积压时使用
  [runners.autoscaler]
    max_instances = 10
    idle_count = 0  # 平时不保留实例
    idle_time = 300
    
    [[runners.autoscaler.policy]]
      periods = ["* * 9-17 * * mon-fri"]  # 工作时间
      idle_count = 2
      idle_time = 600
```

**长期解决方案:**

**1. 优化任务**
```yaml
# 并行化测试
test:
  parallel: 5  # 拆分成5个并行任务
  script:
    - npm test -- --shard=$CI_NODE_INDEX/$CI_NODE_TOTAL
```

**2. 缓存优化**
```yaml
build:
  cache:
    key: ${CI_COMMIT_REF_SLUG}
    paths:
      - node_modules/
      - .gradle/
  script:
    - npm install  # 利用缓存,减少执行时间
    - npm run build
```

**3. 资源配额管理**
```yaml
# 限制每个项目的资源使用
project-a-jobs:
  resource_group: project-a
  variables:
    MAX_CONCURRENT_JOBS: "3"
```

**监控告警:**
```yaml
# Prometheus告警规则
- alert: HighQueueLength
  expr: job_queue_length > 20
  for: 10m
  annotations:
    summary: "任务队列积压严重"
    description: "当前队列长度: {{ $value }}"
    action: "考虑扩容执行器或优化任务"
```

### 4. 如何实现执行器的健康检查和自动恢复?

健康检查和自动恢复确保系统稳定性。

**健康检查实现:**

**心跳机制:**
执行器定期(30-60秒)向服务器发送心跳,包含CPU/内存使用率、活跃任务数等。服务器检测超时执行器并标记为不可用。

**主动探测:**
服务器定期访问执行器的健康检查端点(/health),验证执行器状态。

**Kubernetes健康探针:**
```yaml
apiVersion: apps/v1
kind: Deployment
spec:
  template:
    spec:
      containers:
      - name: runner
        livenessProbe:
          exec:
            command: [gitlab-runner, verify]
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /metrics
            port: 9252
```

**自动恢复策略:**

1. **优雅重启**: 停止接受新任务,等待当前任务完成,然后重启
2. **强制重启**: 保存任务状态,强制停止,重启后重新调度任务
3. **替换执行器**: 如果重启失败,创建新执行器替换

**任务重新调度:**
执行器故障时,将其上的运行中任务标记为失败并重试,排队中任务直接重新调度到其他执行器。

**监控指标:**
- executor_health: 执行器健康状态
- executor_recovery_total: 恢复操作计数

### 5. 容器化执行器和虚拟机执行器各有什么优缺点?

选择合适的执行器类型对性能和成本有重大影响。

**容器化执行器(Docker/Kubernetes)**

**优点:**
1. **快速启动**: 通常<30秒
2. **资源高效**: 共享宿主机内核
3. **环境一致**: 镜像保证环境可复现
4. **易于管理**: 声明式配置,易于扩展

**缺点:**
1. **隔离性较弱**: 共享内核,安全性相对较低
2. **不支持某些场景**: 如需要内核模块、特殊硬件
3. **嵌套限制**: Docker-in-Docker有性能问题

**适用场景:**
```yaml
# 适合容器执行器的场景
build-nodejs:
  image: node:18
  script:
    - npm install
    - npm run build
  # 快速,环境一致,资源高效

test-python:
  image: python:3.11
  script:
    - pip install -r requirements.txt
    - pytest
  # 隔离性好,易于清理
```

**虚拟机执行器(VM-based)**

**优点:**
1. **完全隔离**: 独立内核,安全性高
2. **灵活性强**: 可以运行任何操作系统
3. **支持复杂场景**: 内核模块、特殊驱动等
4. **稳定性好**: 不受宿主机影响

**缺点:**
1. **启动慢**: 通常需要1-3分钟
2. **资源占用大**: 每个VM需要完整OS
3. **成本高**: 需要更多硬件资源
4. **管理复杂**: 镜像大,更新慢

**适用场景:**
```yaml
# 适合VM执行器的场景
build-kernel-module:
  tags:
    - vm
    - linux
  script:
    - make modules
    - insmod mymodule.ko
  # 需要内核级操作

build-windows-app:
  tags:
    - vm
    - windows
  script:
    - msbuild MyApp.sln
  # Windows环境必须用VM

security-scan:
  tags:
    - vm
    - isolated
  script:
    - run-untrusted-code.sh
  # 需要强隔离
```

**混合策略:**

```yaml
# 根据任务特点选择执行器
variables:
  EXECUTOR_STRATEGY: "smart"

.use-container:
  tags:
    - docker
  rules:
    - if: '$CI_JOB_NAME =~ /^(build|test|lint)/'

.use-vm:
  tags:
    - vm
  rules:
    - if: '$CI_JOB_NAME =~ /^(deploy|security)/'

# 标准构建用容器
build:
  extends: .use-container
  script:
    - make build

# 部署用VM(更安全)
deploy:
  extends: .use-vm
  script:
    - kubectl apply -f k8s/
```

**性能对比:**

| 特性 | 容器执行器 | VM执行器 |
|------|-----------|---------|
| 启动时间 | 10-30秒 | 1-3分钟 |
| 资源占用 | 低(共享内核) | 高(独立OS) |
| 隔离性 | 中等 | 强 |
| 安全性 | 中等 | 高 |
| 灵活性 | 中等 | 高 |
| 成本 | 低 | 高 |
| 管理复杂度 | 低 | 中高 |

**选择建议:**

1. **默认使用容器**: 对于90%的CI/CD任务
2. **特殊场景用VM**:
   - 需要内核操作
   - Windows/macOS构建
   - 高安全要求
   - 需要特殊硬件
3. **混合部署**: 
   - 日常构建用容器
   - 发布部署用VM
4. **成本考量**:
   - 资源有限选容器
   - 安全优先选VM